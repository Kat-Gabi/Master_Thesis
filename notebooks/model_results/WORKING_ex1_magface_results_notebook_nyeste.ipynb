{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPERIMENT 1: MagFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load libraries\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import normalize\n",
    "import sys\n",
    "sns.set(style=\"white\")\n",
    "%matplotlib inline\n",
    "sys.path.append('../../utils')\n",
    "from Model_utils.Model_funcs import *\n",
    "from Result_metric_utils.result_metrics import *\n",
    "from Data_proc_utils.Data_proc_funcs import *\n",
    "from DET_utils.DET_plots import *\n",
    "from DET_utils.DET import *\n",
    "from Plotting_stats_utils.plotting_threshold import *\n",
    "from Plotting_stats_utils.stats_tables import *\n",
    "from IPython import embed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MagFace Results\n",
    "\n",
    "This notebook loads the feature vectors from MagFace and run them through the results metrics:\n",
    "FNIR, FPIR, FND, FPD, and GARBE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list_children = '../../data/data_full/feature_vectors/magface_feature_vectors/feat_img_children_full.list'\n",
    "# feature_list_adults = '../../data/data_full/feature_vectors/magface_feature_vectors/feature_vectors_from_adults_bibel_cropped.list'\n",
    "feature_list_adults = '../../data/data_full/feature_vectors/magface_feature_vectors/feature_vectors_from_image_list_adults_bibel_pre_cropped_CROPPED_TEST.list'\n",
    "\n",
    "def load_and_compute_similarity(feature_list, dtype=np.float32):\n",
    "    # Load data\n",
    "    image_names, ids, num_ids, norm_feats = load_magface_vectors(feature_list)\n",
    "\n",
    "    # Convert dtype to reduce memory usage\n",
    "    norm_feats = norm_feats.astype(dtype)\n",
    "\n",
    "    # Compute similarity matrix incrementally if possible\n",
    "    sim_mat = np.dot(norm_feats, norm_feats.T)\n",
    "\n",
    "    return image_names, ids, num_ids, sim_mat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and compute for children\n",
    "image_names_c, ids_c, num_ids_c, sim_mat_c = load_and_compute_similarity(feature_list_children)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load and compute for adults\n",
    "image_names_a, ids_a, num_ids_a, sim_mat_a = load_and_compute_similarity(feature_list_adults)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Dataframes with info, removes names not in magface results\n",
    "children_all = pd.read_csv('../../data/image_info_csvs/final_filtered_children_df_BIBEL.csv')\n",
    "children_all = children_all[children_all.image_name.isin(image_names_c)]\n",
    "\n",
    "adults_all_org = pd.read_csv('../../data/image_info_csvs/final_filtered_adults_df_BIBEL.csv')\n",
    "adults_all = adults_all_org[adults_all_org.image_name.isin(image_names_a)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her = 3\n",
    "image_names_a[her], ids_a[her], num_ids_a[her]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_states = [1,2,3]\n",
    "percentiles = [74, 76, 78, 80, 82, 84, 86, 88, 90, 92, 94, 96, 98]\n",
    "\n",
    "df_all_threshold_x = compute_metrics_ex_1_1(random_states, percentiles, children_all, adults_all, image_names_c, image_names_a, sim_mat_c, sim_mat_a, num_ids_c, num_ids_a, ids_c, ids_a, balance_child_data, balance_adults_data_enrolled, compute_fnir, compute_fpir, GARBE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_threshold_metrics_ex_1_1(df_all_threshold_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GET METRICS 10 TIMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "random_states = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "\n",
    "df_all_results, sim_mat_dict_all_magface_ex1_1 = evaluate_metrics_ex_1_1(\n",
    "    random_states, children_all, adults_all, image_names_c, image_names_a,\n",
    "    sim_mat_c, sim_mat_a, num_ids_c, num_ids_a, ids_c, ids_a, balance_child_data,\n",
    "    balance_adults_data_enrolled, compute_fnir, compute_fpir, GARBE, remove_ones, 0.315\n",
    ")\n",
    "\n",
    "df_all_results.describe().applymap(lambda x: f\"{x:.3f}\")\n",
    "df_all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_states = [1,2,3,4,5,6,7,8,9,10]\n",
    "# sim_mat_dict_all_magface_ex1_1 = {}\n",
    "# FNIR_c_list=[]\n",
    "# FNIR_a_list=[]\n",
    "# FPIR_c_list=[]\n",
    "# FPIR_a_list=[]\n",
    "# FPD_list=[]\n",
    "# FND_list=[]\n",
    "# GARBE_list=[]\n",
    "# threshold_list = []\n",
    "\n",
    "# for random_state_i in random_states:\n",
    "\n",
    "#     ### Load children and adults balanced data ###\n",
    "#     children_balanced_df_i = balance_child_data(children_all, print_stats=False, random_state=random_state_i)\n",
    "#     adults_balanced_df_i = balance_adults_data_enrolled(children_balanced_df_i, adults_all, print_stats=False, random_state=random_state_i)\n",
    "\n",
    "\n",
    "\n",
    "#     ### All reference image names, enrolled and non-enrolled image names - children ###\n",
    "#     c_mates = children_balanced_df_i.groupby(\"identity_name\").agg({'identity_name': ['count']})\n",
    "#     enrolled_identity_names_c = c_mates[c_mates[('identity_name', 'count')] > 1].index\n",
    "#     enrolled_image_names_c = list(children_balanced_df_i[children_balanced_df_i[\"identity_name\"].isin(enrolled_identity_names_c)].image_name)\n",
    "#     non_enrolled_identity_names_c = c_mates[c_mates[('identity_name', 'count')] == 1].index\n",
    "#     non_enrolled_image_names_c = list(children_balanced_df_i[children_balanced_df_i[\"identity_name\"].isin(non_enrolled_identity_names_c)].image_name)\n",
    "#     all_reference_image_names_c = list(children_balanced_df_i.image_name)\n",
    "\n",
    "\n",
    "#     ### All reference image names, enrolled and non-enrolled image names - adults ###\n",
    "#     a_mates = adults_balanced_df_i.groupby(\"identity_name\").agg({'identity_name': ['count']})\n",
    "#     enrolled_identity_names_a = a_mates[a_mates[('identity_name', 'count')] > 1].index\n",
    "#     enrolled_image_names_a = list(adults_balanced_df_i[adults_balanced_df_i[\"identity_name\"].isin(enrolled_identity_names_a)].image_name)\n",
    "#     non_enrolled_identity_names_a = a_mates[a_mates[('identity_name', 'count')] == 1].index\n",
    "#     non_enrolled_image_names_a = list(adults_balanced_df_i[adults_balanced_df_i[\"identity_name\"].isin(non_enrolled_identity_names_a)].image_name)\n",
    "#     all_reference_image_names_a = list(adults_balanced_df_i.image_name)\n",
    "\n",
    "\n",
    "\n",
    "#     ### Similarity matrices for ids in reference database ###\n",
    "#     indices_c_all_reference = [image_names_c.index(name) for name in all_reference_image_names_c]\n",
    "#     indices_a_all_reference = [image_names_a.index(name) for name in all_reference_image_names_a]\n",
    "\n",
    "\n",
    "\n",
    "#     # Extract corresponding columns from the similarity matrix\n",
    "#     sim_mat_c_reference_cols = sim_mat_c[:, indices_c_all_reference]\n",
    "\n",
    "\n",
    "#     sim_mat_a_reference_cols = sim_mat_a[:, indices_a_all_reference]\n",
    "\n",
    "#     # Extract corresponding rows from the numerical ids\n",
    "#     num_ids_c_reference = num_ids_c[indices_c_all_reference]\n",
    "#     num_ids_a_reference = num_ids_a[indices_a_all_reference]\n",
    "\n",
    "\n",
    "#     ### Similarity matrices for non-enrolled ids ###\n",
    "#     # Get indices of all feature and numerical id elements that are non-enrolled  ids\n",
    "#     indices_c_non_enrolled = [image_names_c.index(name) for name in non_enrolled_image_names_c]\n",
    "#     indices_a_non_enrolled = [image_names_a.index(name) for name in non_enrolled_image_names_a]\n",
    "\n",
    "\n",
    "#     # Extract corresponding rows from the similarity matrix\n",
    "#     sim_mat_c_non_enrolled_0 = sim_mat_c_reference_cols[indices_c_non_enrolled]\n",
    "#     sim_mat_a_non_enrolled_0 = sim_mat_a_reference_cols[indices_a_non_enrolled]\n",
    "\n",
    "#     # Extract corresponding rows from the numerical ids\n",
    "#     num_ids_c_non_enrolled = num_ids_c[indices_c_non_enrolled]\n",
    "#     num_ids_a_non_enrolled = num_ids_a[indices_a_non_enrolled]\n",
    "\n",
    "\n",
    "#     ### Similarity matrices for enrolled ids ###\n",
    "#     # Get indices of all feature and numerical id elements that are enrolled ids\n",
    "#     indices_c_enrolled = [image_names_c.index(name) for name in enrolled_image_names_c]\n",
    "#     indices_a_enrolled = [image_names_a.index(name) for name in enrolled_image_names_a]\n",
    "\n",
    "#     # Extract corresponding rows from the similarity matrix\n",
    "#     sim_mat_c_enrolled_0 = sim_mat_c[np.ix_(indices_c_enrolled, indices_c_enrolled)] # only enrolled columns and rows\n",
    "#     sim_mat_a_enrolled_0 = sim_mat_a[np.ix_(indices_a_enrolled, indices_a_enrolled)]\n",
    "\n",
    "#     # Extract corresponding rows from the numerical ids\n",
    "#     num_ids_c_enrolled = num_ids_c[indices_c_enrolled]\n",
    "#     num_ids_a_enrolled = num_ids_a[indices_a_enrolled]\n",
    "\n",
    "\n",
    "#     ### DET THINGS ###\n",
    "\n",
    "#     # thold = (np.percentile(sim_mat_c,90)+np.percentile(sim_mat_a,90))/2\n",
    "#     # thold = ((np.percentile(sim_mat_c_non_enrolled_0,90) + (np.percentile(sim_mat_a_non_enrolled_0,90)))/2 + (np.percentile(sim_mat_c_enrolled_0,90) + (np.percentile(sim_mat_a_enrolled_0,90)))/2 )/2\n",
    "#     # thold = np.percentile(sim_mat_a, 99)\n",
    "#     thold = 0.31\n",
    "\n",
    "#     ### Evaluation metrics ###\n",
    "#     # FNIR\n",
    "#     FNIR_c, sim_mat_c_enrolled = compute_fnir(sim_mat_c_enrolled_0, sim_mat_c, enrolled_identity_names_c, num_ids_c_enrolled, ids_c, thold=thold)\n",
    "#     FNIR_a, sim_mat_a_enrolled = compute_fnir(sim_mat_a_enrolled_0, sim_mat_a, enrolled_identity_names_a, num_ids_a_enrolled, ids_a, thold=thold)\n",
    "#     # FPIR\n",
    "#     FPIR_c = compute_fpir(sim_mat_c_non_enrolled_0, num_ids_c_non_enrolled, num_ids_c_reference, thold=thold)\n",
    "#     FPIR_a = compute_fpir(sim_mat_a_non_enrolled_0, num_ids_a_non_enrolled, num_ids_a_reference, thold=thold)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     # OBS maybe compute Garbe outside funtion to choose a good alpha?\n",
    "#     alpha_garbe = 0.25\n",
    "#     FPD_i, FND_i, GARBE_i = GARBE(FNIR_c, FNIR_a, FPIR_c, FPIR_a, alpha=alpha_garbe)\n",
    "\n",
    "\n",
    "#     FNIR_c_list.append(FNIR_c)\n",
    "#     FNIR_a_list.append(FNIR_a)\n",
    "#     FPIR_c_list.append(FPIR_c)\n",
    "#     FPIR_a_list.append(FPIR_a)\n",
    "#     FPD_list.append(FPD_i)\n",
    "#     FND_list.append(FND_i)\n",
    "#     GARBE_list.append(GARBE_i)\n",
    "#     threshold_list.append(thold)\n",
    "\n",
    "#     sim_mat_dict_all_magface_ex1_1['sim_mat_c_enrolled_iteration_{}'.format(random_state_i)]=sim_mat_c_enrolled\n",
    "#     sim_mat_dict_all_magface_ex1_1['sim_mat_a_enrolled_iteration_{}'.format(random_state_i)]=sim_mat_a_enrolled\n",
    "#     sim_mat_dict_all_magface_ex1_1['sim_mat_c_non_enrolled_iteration_{}'.format(random_state_i)]=remove_ones(sim_mat_c_non_enrolled_0)\n",
    "#     sim_mat_dict_all_magface_ex1_1['sim_mat_a_non_enrolled_iteration_{}'.format(random_state_i)]=remove_ones(sim_mat_a_non_enrolled_0)\n",
    "\n",
    "\n",
    "#     print(\"done\")\n",
    "\n",
    "# data = {\n",
    "#     'Iteration': random_states,\n",
    "#     'FNIR_c': FNIR_c_list,\n",
    "#     'FNIR_a': FNIR_a_list,\n",
    "#     'FPIR_c': FPIR_c_list,\n",
    "#     'FPIR_a': FPIR_a_list,\n",
    "#     'FPD': FPD_list,\n",
    "#     'FND': FND_list,\n",
    "#     'GARBE': GARBE_list,\n",
    "#     'Threshold': threshold_list\n",
    "# }\n",
    "# df_all_results = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_results.to_csv('results_10_experiment_1_1_magface.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add together all\n",
    "\n",
    "# make one  big array out of all arays named f'sim_mat_dict_all_magface_ex1_1['sim_mat_c_enrolled_iteration_{i}']' for i from 1 to 10\n",
    "# List to hold all the arrays\n",
    "sim_mat_c_enrolled_iterations = []\n",
    "\n",
    "# Loop to access each array and append it to the list\n",
    "for i in range(1, 11):\n",
    "    key = f'sim_mat_c_enrolled_iteration_{i}'\n",
    "    if key in sim_mat_dict_all_magface_ex1_1:\n",
    "        sim_mat_c_enrolled_iterations.append(sim_mat_dict_all_magface_ex1_1[key])\n",
    "\n",
    "# Concatenate all arrays into one big array\n",
    "sim_mat_c_enrolled_iterations_all = np.concatenate(sim_mat_c_enrolled_iterations)\n",
    "sim_mat_c_enrolled_iterations_all = pd.DataFrame(sim_mat_c_enrolled_iterations_all)\n",
    "sim_mat_c_enrolled_iterations_all.to_csv('sim_mat_c_enrolled_iterations_all.csv', index=False)\n",
    "# Print the big array\n",
    "print(len(sim_mat_c_enrolled_iterations_all))\n",
    "\n",
    "\n",
    "\n",
    "# Add together all\n",
    "\n",
    "# make one  big array out of all arays named f'sim_mat_dict_all_magface_ex1_1['sim_mat_c_enrolled_iteration_{i}']' for i from 1 to 10\n",
    "\n",
    "# List to hold all the arrays\n",
    "sim_mat_a_enrolled_iterations = []\n",
    "\n",
    "# Loop to access each array and append it to the list\n",
    "for i in range(1, 11):\n",
    "    key = f'sim_mat_a_enrolled_iteration_{i}'\n",
    "    if key in sim_mat_dict_all_magface_ex1_1:\n",
    "        sim_mat_a_enrolled_iterations.append(sim_mat_dict_all_magface_ex1_1[key])\n",
    "\n",
    "# Concatenate all arrays into one big array\n",
    "sim_mat_a_enrolled_iterations_all = np.concatenate(sim_mat_a_enrolled_iterations)\n",
    "sim_mat_a_enrolled_iterations_all = pd.DataFrame(sim_mat_a_enrolled_iterations_all)\n",
    "sim_mat_a_enrolled_iterations_all.to_csv('sim_mat_a_enrolled_iterations_all.csv', index=False)\n",
    "\n",
    "\n",
    "# Print the big array\n",
    "print(len(sim_mat_a_enrolled_iterations_all))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add together all\n",
    "\n",
    "# make one  big array out of all arays named f'sim_mat_dict_all_magface_ex1_1['sim_mat_c_enrolled_iteration_{i}']' for i from 1 to 10\n",
    "\n",
    "# List to hold all the arrays\n",
    "sim_mat_c_non_enrolled_iterations = []\n",
    "\n",
    "# Loop to access each array and append it to the list\n",
    "for i in range(1, 11):\n",
    "    key = f'sim_mat_c_non_enrolled_iteration_{i}'\n",
    "    if key in sim_mat_dict_all_magface_ex1_1:\n",
    "        sim_mat_c_non_enrolled_iterations.append(sim_mat_dict_all_magface_ex1_1[key])\n",
    "\n",
    "sim_mat_c_non_enrolled_iterations_all = np.concatenate(sim_mat_c_non_enrolled_iterations)\n",
    "sim_mat_c_non_enrolled_iterations_all = pd.DataFrame(sim_mat_c_non_enrolled_iterations_all)\n",
    "sim_mat_c_non_enrolled_iterations_all.to_csv('sim_mat_c_non_enrolled_iterations_all.csv', index=False)\n",
    "# Print the big array\n",
    "print(len(sim_mat_c_non_enrolled_iterations_all))\n",
    "\n",
    "\n",
    "# Add together all\n",
    "\n",
    "# make one  big array out of all arays named f'sim_mat_dict_all_magface_ex1_1['sim_mat_c_enrolled_iteration_{i}']' for i from 1 to 10\n",
    "\n",
    "# List to hold all the arrays\n",
    "sim_mat_a_non_enrolled_iterations = []\n",
    "\n",
    "# Loop to access each array and append it to the list\n",
    "for i in range(1, 11):\n",
    "    key = f'sim_mat_a_non_enrolled_iteration_{i}'\n",
    "    if key in sim_mat_dict_all_magface_ex1_1:\n",
    "        sim_mat_a_non_enrolled_iterations.append(sim_mat_dict_all_magface_ex1_1[key])\n",
    "\n",
    "sim_mat_a_non_enrolled_iterations_all = np.concatenate(sim_mat_a_non_enrolled_iterations)\n",
    "sim_mat_a_non_enrolled_iterations_all = pd.DataFrame(sim_mat_a_non_enrolled_iterations_all)\n",
    "sim_mat_a_non_enrolled_iterations_all.to_csv('sim_mat_a_non_enrolled_iterations_all.csv', index=False)\n",
    "\n",
    "# Print the big array\n",
    "print(len(sim_mat_a_non_enrolled_iterations_all))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_results.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading pre-saved stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_mat_c_enrolled_iterations_all = (pd.read_csv('sim_mat_c_enrolled_iterations_all.csv')).values.flatten()\n",
    "sim_mat_a_enrolled_iterations_all = (pd.read_csv('sim_mat_a_enrolled_iterations_all.csv')).values.flatten()\n",
    "sim_mat_c_non_enrolled_iterations_all = (pd.read_csv('sim_mat_c_non_enrolled_iterations_all.csv')).values.flatten()\n",
    "sim_mat_a_non_enrolled_iterations_all = (pd.read_csv('sim_mat_a_non_enrolled_iterations_all.csv')).values.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_results = pd.read_csv('results_10_experiment_1_1_magface.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "The FNIR values for both groups are relatively close to each other, with FNIR_c ranging from approximately 0.338 to 0.377 and FNIR_a ranging from approximately 0.277 to 0.310.\n",
    "\n",
    "\n",
    "Larger variation in the FPIR. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From DET utils - check import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import describe, gaussian_kde\n",
    "import math\n",
    "\n",
    "def descriptive_statistics(mated_scores, nonmated_scores):\n",
    "    stats_labels = [\"Observations\", \"Minimum\", \"Maximum\", \"Mean\", \"St. Dev.\", \"Skewness\", \"Ex. Kurtosis\"]\n",
    "    mated_stats = describe(mated_scores)\n",
    "    mated_stats = [mated_stats.nobs, mated_stats.minmax[0], mated_stats.minmax[1], mated_stats.mean, math.sqrt(mated_stats.variance), mated_stats.skewness, mated_stats.kurtosis]\n",
    "    nonmated_stats = describe(nonmated_scores)\n",
    "    nonmated_stats = [nonmated_stats.nobs, nonmated_stats.minmax[0], nonmated_stats.minmax[1], nonmated_stats.mean, math.sqrt(nonmated_stats.variance), nonmated_stats.skewness, nonmated_stats.kurtosis]\n",
    "\n",
    "    stats_system_df = pd.DataFrame(np.array([stats_labels, mated_stats, nonmated_stats]).T, columns=[\"Statistic\", \"Mated\", \"Non-mated\"])\n",
    "    stats_system_df = stats_system_df.astype({\"Statistic\": str, \"Mated\": float, \"Non-mated\": float})\n",
    "    return stats_system_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_enroll_a =(np.round(len(sim_mat_a_enrolled_iterations_all)/1.5)).astype(int)\n",
    "mated_scores1 = sim_mat_a_enrolled_iterations_all\n",
    "end_non_enroll_a = (np.round(len(sim_mat_a_non_enrolled_iterations_all)/1.5)).astype(int)\n",
    "nonmated_scores1 = sim_mat_a_non_enrolled_iterations_all\n",
    "scores_type1 = \"similarity\"\n",
    "stats_system1_df = descriptive_statistics(mated_scores1, nonmated_scores1)\n",
    "display(stats_system1_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "end_enroll_c =(np.round(len(sim_mat_c_enrolled_iterations_all)/2)).astype(int)\n",
    "# mated_scores2 = sim_mat_c_enrolled_iterations_all[:end_enroll_c]\n",
    "mated_scores2 = sim_mat_c_enrolled_iterations_all\n",
    "end_non_enroll_c = (np.round(len(sim_mat_c_non_enrolled_iterations_all)/2)).astype(int)\n",
    "# nonmated_scores2 = sim_mat_c_non_enrolled_iterations_all[:end_non_enroll_c]\n",
    "nonmated_scores2 = sim_mat_c_non_enrolled_iterations_all\n",
    "scores_type2 = \"similarity\"\n",
    "stats_system2_df = descriptive_statistics(mated_scores2, nonmated_scores2)\n",
    "display(stats_system2_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mated_colour = \"green\"\n",
    "mated_label = \"Mated scores\"\n",
    "nonmated_colour = \"red\"\n",
    "nonmated_label = \"Non-mated scores\"\n",
    "\n",
    "figure_size = (12,6)\n",
    "alpha_shade = 0.25\n",
    "alpha_fill = 1.0\n",
    "linewidth = 2\n",
    "legend_loc = \"upper left\"\n",
    "legend_anchor = (1.0, 1.02)\n",
    "legend_cols = 1\n",
    "legend_fontsize = 12\n",
    "label_fontsize = 16\n",
    "\n",
    "threshold_colour = \"black\"\n",
    "threshold_style = \"--\"\n",
    "round_digits = 5\n",
    "sns.set(style=\"white\", palette=\"muted\", color_codes=True)\n",
    "plt.rc(\"axes\", axisbelow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_histogram(mated_scores, nonmated_scores, normalise=True, savename=None):\n",
    "#     def normalise_scores(distribution):\n",
    "#         return np.ones_like(distribution) / len(distribution)\n",
    "#     plt.figure(figsize=figure_size)\n",
    "#     if normalise:\n",
    "#         plt.hist(mated_scores, bins=50, weights=normalise_scores(mated_scores), color='red', alpha=0.5, label=mated_label)\n",
    "#         plt.hist(nonmated_scores, bins=30, weights=normalise_scores(nonmated_scores), color='green', alpha=0.5, label=nonmated_label)\n",
    "#         xlabel = \"Probability Density\"\n",
    "#     else:\n",
    "#         plt.hist(mated_scores, bins=50, color='red', alpha=0.5, label=mated_label)\n",
    "#         plt.hist(nonmated_scores, bins=30, color='green', alpha=0.5, label=nonmated_label)\n",
    "#         xlabel = \"Count\"\n",
    "#     plt.xlabel(\"Comparison Score\", size=label_fontsize)\n",
    "#     plt.ylabel(xlabel, size=label_fontsize)\n",
    "#     plt.grid(True)\n",
    "#     plt.legend(loc=legend_loc, bbox_to_anchor=legend_anchor, ncol=legend_cols, fontsize=legend_fontsize)\n",
    "\n",
    "#     if savename is not None:\n",
    "#         plt.savefig(savename, bbox_inches=\"tight\")\n",
    "#         plt.cla()\n",
    "#         plt.clf()\n",
    "#         plt.close()\n",
    "#     else:\n",
    "#         plt.show()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_histogram(mated_scores, nonmated_scores, normalise=True, savename=None, title=\"Histogram\"):\n",
    "    def normalise_scores(distribution):\n",
    "        return np.ones_like(distribution) / len(distribution)\n",
    "\n",
    "    mated_mean = np.mean(mated_scores)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))  # Replace 'figure_size' with a specific size if not defined\n",
    "\n",
    "    if normalise:\n",
    "        plt.hist(mated_scores, bins=50, weights=normalise_scores(mated_scores), color='red', alpha=0.5, label='Mated Scores')  # Replace 'mated_label' with 'Mated Scores'\n",
    "        plt.hist(nonmated_scores, bins=30, weights=normalise_scores(nonmated_scores), color='green', alpha=0.5, label='Non-mated Scores')  # Replace 'nonmated_label' with 'Non-mated Scores'\n",
    "        ylabel = \"Probability Density\"\n",
    "    else:\n",
    "        plt.hist(mated_scores, bins=50, color='red', alpha=0.5, label='Mated Scores')\n",
    "        plt.hist(nonmated_scores, bins=30, color='green', alpha=0.5, label='Non-mated Scores')\n",
    "        ylabel = \"Count\"\n",
    "\n",
    "    plt.axvline(mated_mean, color='darkred', linestyle='--', linewidth=2, label=f'Mated Mean: {mated_mean:.2f}')\n",
    "\n",
    "    plt.xlabel(\"Comparison Score\", size=12)  # Replace 'label_fontsize' with 12 or any preferred size\n",
    "    plt.ylabel(ylabel, size=12)  # Replace 'label_fontsize' with 12 or any preferred size\n",
    "    plt.title(title, size=14)  # Title added here\n",
    "    plt.grid(True)\n",
    "    plt.legend(loc='upper right', bbox_to_anchor=(1, 1), ncol=1, fontsize=10)  # Adjust legend parameters as needed\n",
    "\n",
    "    if savename is not None:\n",
    "        plt.savefig(savename, bbox_inches=\"tight\")\n",
    "        plt.cla()\n",
    "        plt.clf()\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_histogram(mated_scores1, nonmated_scores1, normalise=True, title = 'Adults - MagFace ex. 1.1 ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram(mated_scores2, nonmated_scores2, normalise=True, title = 'Children - MagFace ex. 1.1 ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different thresholds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_states = [1,2,3]\n",
    "FNIR_c_list=[]\n",
    "FNIR_a_list=[]\n",
    "FPIR_c_list=[]\n",
    "FPIR_a_list=[]\n",
    "FPD_list=[]\n",
    "FND_list=[]\n",
    "GARBE_list=[]\n",
    "threshold_list = []\n",
    "# percentiles = np.arange(78, 100, 2)\n",
    "percentile = 66\n",
    "\n",
    "for random_state_i in random_states:\n",
    "\n",
    "    ### Load children and adults balanced data ###\n",
    "    children_balanced_df_i = balance_child_data(children_all, print_stats=False, random_state=random_state_i)\n",
    "    adults_balanced_df_i = balance_adults_data_enrolled(children_balanced_df_i, adults_all, print_stats=False, random_state=random_state_i)\n",
    "\n",
    "\n",
    "\n",
    "    ### All reference image names, enrolled and non-enrolled image names - children ###\n",
    "    c_mates = children_balanced_df_i.groupby(\"identity_name\").agg({'identity_name': ['count']})\n",
    "    enrolled_identity_names_c = c_mates[c_mates[('identity_name', 'count')] > 1].index\n",
    "    enrolled_image_names_c = list(children_balanced_df_i[children_balanced_df_i[\"identity_name\"].isin(enrolled_identity_names_c)].image_name)\n",
    "    non_enrolled_identity_names_c = c_mates[c_mates[('identity_name', 'count')] == 1].index\n",
    "    non_enrolled_image_names_c = list(children_balanced_df_i[children_balanced_df_i[\"identity_name\"].isin(non_enrolled_identity_names_c)].image_name)\n",
    "    all_reference_image_names_c = list(children_balanced_df_i.image_name)\n",
    "\n",
    "\n",
    "    ### All reference image names, enrolled and non-enrolled image names - adults ###\n",
    "    a_mates = adults_balanced_df_i.groupby(\"identity_name\").agg({'identity_name': ['count']})\n",
    "    enrolled_identity_names_a = a_mates[a_mates[('identity_name', 'count')] > 1].index\n",
    "    enrolled_image_names_a = list(adults_balanced_df_i[adults_balanced_df_i[\"identity_name\"].isin(enrolled_identity_names_a)].image_name)\n",
    "    non_enrolled_identity_names_a = a_mates[a_mates[('identity_name', 'count')] == 1].index\n",
    "    non_enrolled_image_names_a = list(adults_balanced_df_i[adults_balanced_df_i[\"identity_name\"].isin(non_enrolled_identity_names_a)].image_name)\n",
    "    all_reference_image_names_a = list(adults_balanced_df_i.image_name)\n",
    "\n",
    "\n",
    "\n",
    "    ### Similarity matrices for ids in reference database ###\n",
    "    indices_c_all_reference = [image_names_c.index(name) for name in all_reference_image_names_c]\n",
    "    indices_a_all_reference = [image_names_a.index(name) for name in all_reference_image_names_a]\n",
    "\n",
    "\n",
    "\n",
    "    # Extract corresponding columns from the similarity matrix\n",
    "    sim_mat_c_reference_cols = sim_mat_c[:, indices_c_all_reference]\n",
    "\n",
    "\n",
    "    sim_mat_a_reference_cols = sim_mat_a[:, indices_a_all_reference]\n",
    "\n",
    "    # Extract corresponding rows from the numerical ids\n",
    "    num_ids_c_reference = num_ids_c[indices_c_all_reference]\n",
    "    num_ids_a_reference = num_ids_a[indices_a_all_reference]\n",
    "\n",
    "\n",
    "    ### Similarity matrices for non-enrolled ids ###\n",
    "    # Get indices of all feature and numerical id elements that are non-enrolled  ids\n",
    "    indices_c_non_enrolled = [image_names_c.index(name) for name in non_enrolled_image_names_c]\n",
    "    indices_a_non_enrolled = [image_names_a.index(name) for name in non_enrolled_image_names_a]\n",
    "\n",
    "\n",
    "    # Extract corresponding rows from the similarity matrix\n",
    "    sim_mat_c_non_enrolled_0 = sim_mat_c_reference_cols[indices_c_non_enrolled]\n",
    "    sim_mat_a_non_enrolled_0 = sim_mat_a_reference_cols[indices_a_non_enrolled]\n",
    "\n",
    "    # Extract corresponding rows from the numerical ids\n",
    "    num_ids_c_non_enrolled = num_ids_c[indices_c_non_enrolled]\n",
    "    num_ids_a_non_enrolled = num_ids_a[indices_a_non_enrolled]\n",
    "\n",
    "\n",
    "    ### Similarity matrices for enrolled ids ###\n",
    "    # Get indices of all feature and numerical id elements that are enrolled ids\n",
    "    indices_c_enrolled = [image_names_c.index(name) for name in enrolled_image_names_c]\n",
    "    indices_a_enrolled = [image_names_a.index(name) for name in enrolled_image_names_a]\n",
    "\n",
    "    # Extract corresponding rows from the similarity matrix\n",
    "    sim_mat_c_enrolled_0 = sim_mat_c[np.ix_(indices_c_enrolled, indices_c_enrolled)] # only enrolled columns and rows\n",
    "    sim_mat_a_enrolled_0 = sim_mat_a[np.ix_(indices_a_enrolled, indices_a_enrolled)]\n",
    "\n",
    "    # Extract corresponding rows from the numerical ids\n",
    "    num_ids_c_enrolled = num_ids_c[indices_c_enrolled]\n",
    "    num_ids_a_enrolled = num_ids_a[indices_a_enrolled]\n",
    "\n",
    "\n",
    "    ### DET THINGS ###\n",
    "\n",
    "    thold = (np.percentile(sim_mat_c,percentile)+np.percentile(sim_mat_a,percentile))/2\n",
    "    # thold = ((np.percentile(sim_mat_c_non_enrolled_0,percentile) + (np.percentile(sim_mat_a_non_enrolled_0,percentile)))/2 + (np.percentile(sim_mat_c_enrolled_0,percentile) + (np.percentile(sim_mat_a_enrolled_0,percentile)))/2 )/2\n",
    "    # thold = np.percentile(sim_mat_a, 99)\n",
    "\n",
    "    ### Evaluation metrics ###\n",
    "    # FNIR\n",
    "    FNIR_c, sim_mat_c_enrolled = compute_fnir(sim_mat_c_enrolled_0, sim_mat_c, enrolled_identity_names_c, num_ids_c_enrolled, ids_c, thold=thold)\n",
    "    FNIR_a, sim_mat_a_enrolled = compute_fnir(sim_mat_a_enrolled_0, sim_mat_a, enrolled_identity_names_a, num_ids_a_enrolled, ids_a, thold=thold)\n",
    "    # FPIR\n",
    "    FPIR_c = compute_fpir(sim_mat_c_non_enrolled_0, num_ids_c_non_enrolled, num_ids_c_reference, thold=thold)\n",
    "    FPIR_a = compute_fpir(sim_mat_a_non_enrolled_0, num_ids_a_non_enrolled, num_ids_a_reference, thold=thold)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # OBS maybe compute Garbe outside funtion to choose a good alpha?\n",
    "    alpha_garbe = 0.25\n",
    "    FPD_i, FND_i, GARBE_i = GARBE(FNIR_c, FNIR_a, FPIR_c, FPIR_a, alpha=alpha_garbe)\n",
    "\n",
    "\n",
    "    FNIR_c_list.append(FNIR_c)\n",
    "    FNIR_a_list.append(FNIR_a)\n",
    "    FPIR_c_list.append(FPIR_c)\n",
    "    FPIR_a_list.append(FPIR_a)\n",
    "    FPD_list.append(FPD_i)\n",
    "    FND_list.append(FND_i)\n",
    "    GARBE_list.append(GARBE_i)\n",
    "    threshold_list.append(thold)\n",
    "\n",
    "    print(\"done\")\n",
    "\n",
    "data = {\n",
    "    'Iteration': random_states,\n",
    "    'FNIR_c': FNIR_c_list,\n",
    "    'FNIR_a': FNIR_a_list,\n",
    "    'FPIR_c': FPIR_c_list,\n",
    "    'FPIR_a': FPIR_a_list,\n",
    "    'FPD': FPD_list,\n",
    "    'FND': FND_list,\n",
    "    'GARBE': GARBE_list,\n",
    "    'Threshold': threshold_list\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_threshold_66 = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_threshold_plot = pd.concat([data_threshold_plot, df_all_threshold_66 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_threshold_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_threshold_plot.sort_values(by = 'Threshold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by threshold\n",
    "plot_df = data_threshold_plot.groupby('Threshold').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df.to_csv('magface_1_1_threshold_FNIR_plot.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting FNIR and FPIR vs. Threshold\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "# Plot FNIR\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(plot_df.index, plot_df['FNIR_c'], 'r-', label='Children')\n",
    "plt.plot(plot_df.index, plot_df['FNIR_a'], 'c-', label='Adults')\n",
    "# plt.yscale('log')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('FNIR')\n",
    "plt.title('FNIR vs Threshold')\n",
    "plt.legend()\n",
    "\n",
    "# Plot FPIR\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(plot_df.index, plot_df['FPIR_c'], 'r-', label='Children')\n",
    "plt.plot(plot_df.index, plot_df['FPIR_a'], 'c-', label='Adults')\n",
    "# plt.yscale('log')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('FPIR')\n",
    "plt.title('FPIR vs Threshold')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "decide that an FNIR of 0.05 hence 5% is acceptable. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DET curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mated_kde, mated_pos, mated_min, mated_max = get_kde(mated_scores1)\n",
    "nonmated_kde, nonmated_pos, nonmated_min, nonmated_max = get_kde(nonmated_scores1)\n",
    "plt.figure(figsize=figure_size)\n",
    "plt.plot(mated_pos, mated_kde(mated_pos), linewidth=linewidth, color=mated_colour, label=mated_label)\n",
    "plt.plot(nonmated_pos, nonmated_kde(nonmated_pos), linewidth=linewidth, color=nonmated_colour, label=nonmated_label)\n",
    "plt.xlabel(\"Score\", size=label_fontsize)\n",
    "plt.ylabel(\"Probability Density\", size=label_fontsize)\n",
    "plt.grid(True)\n",
    "plt.legend(loc=legend_loc, bbox_to_anchor=legend_anchor, ncol=legend_cols, fontsize=legend_fontsize)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_prime_system1 = d_prime(mated_scores1, nonmated_scores1)\n",
    "print(\"d' child =\", round(d_prime_system1, round_digits))\n",
    "\n",
    "d_prime_system2 = d_prime(mated_scores2, nonmated_scores2)\n",
    "print(\"d' adult =\", round(d_prime_system2, round_digits))\n",
    "\n",
    "# d_prime_system3 = d_prime(mated_scores3, nonmated_scores3)\n",
    "# print(\"d' canonical =\", round(d_prime_system3, round_digits))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold1 = 0.31\n",
    "kde_with_threshold(mated_scores1, nonmated_scores1, scores_type1, threshold1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold2 = 0.31\n",
    "kde_with_threshold(mated_scores2, nonmated_scores2, scores_type2, threshold2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_name1 = 'Adults'\n",
    "system_name2 = 'Children'\n",
    "\n",
    "det = DET(biometric_evaluation_type='identification', abbreviate_axes=True, plot_eer_line=True, plot_title=\"Children vs adults\")\n",
    "det.x_limits = np.array([1e-4, .5])\n",
    "det.y_limits = np.array([1e-4, .5])\n",
    "det.x_ticks = np.array([1e-3, 1e-2, 5e-2, 20e-2, 40e-2])\n",
    "det.x_ticklabels = np.array(['0.1', '1', '5', '20', '40'])\n",
    "det.y_ticks = np.array([1e-3, 1e-2, 5e-2, 20e-2, 40e-2])\n",
    "det.y_ticklabels = np.array(['0.1', '1', '5', '20', '40'])\n",
    "det.create_figure()\n",
    "det.plot(tar=adjust_scores_for_DET(mated_scores1, scores_type1), non=adjust_scores_for_DET(nonmated_scores1, scores_type1), label=system_name1)\n",
    "det.plot(tar=adjust_scores_for_DET(mated_scores2, scores_type2), non=adjust_scores_for_DET(nonmated_scores2, scores_type2), label=system_name2)\n",
    "det.legend_on(loc=\"upper right\")\n",
    "det.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "best_master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
