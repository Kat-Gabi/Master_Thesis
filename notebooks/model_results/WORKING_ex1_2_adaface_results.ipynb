{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPERIMENT 1.2: AdaFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load libraries\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import normalize\n",
    "import sys\n",
    "sns.set(style=\"white\")\n",
    "%matplotlib inline\n",
    "sys.path.append('../../utils')\n",
    "from Model_utils.Model_funcs import *\n",
    "from Result_metric_utils.result_metrics import *\n",
    "from Data_proc_utils.Data_proc_funcs import *\n",
    "from DET_utils.DET_plots import *\n",
    "from DET_utils.DET import *\n",
    "from Plotting_stats_utils.plotting_threshold import *\n",
    "from Plotting_stats_utils.stats_tables import *\n",
    "\n",
    "from IPython import embed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save figures\n",
    "from matplotlib import pyplot as plt\n",
    "save_fig_path = '../../figures/ada_1_2/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list_children = '../../data/data_full/feature_vectors/adaface_feature_vectors/1.1/similarity_scores_children_filtered_bibel_FINAL_INFERENCE_baseline1.pt'\n",
    "\n",
    "\n",
    "image_names_c, ids_c, num_ids_c, norm_feats_c = load_adaface_vectors(feature_list_children)\n",
    "image_names_a, ids_a, num_ids_a, norm_feats_a = image_names_c, ids_c, num_ids_c, norm_feats_c\n",
    "# ids_a = [\"_\".join(x.split(\"_\")[1:]) for x in ids_a]\n",
    "\n",
    "\n",
    "# Similarity matrices from adaface - all\n",
    "sim_mat_c = np.dot(norm_feats_c, norm_feats_c.T)\n",
    "sim_mat_a = np.dot(norm_feats_a, norm_feats_a.T)\n",
    "\n",
    "\n",
    "# Dataframes with info, removes names not in magface results\n",
    "children_all = pd.read_csv('../../data/image_info_csvs/final_filtered_canonical_df_BIBLE.csv')\n",
    "children_all = children_all[children_all.image_name.isin(image_names_c)]\n",
    "\n",
    "adults_all_org = pd.read_csv('../../data/image_info_csvs/final_filtered_children_df_BIBEL.csv')\n",
    "adults_all = adults_all_org[adults_all_org.image_name.isin(image_names_a)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the threshold\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_states = [1,2]\n",
    "# percentiles = np.arange(0.0, 1.0, 0.01).tolist()\n",
    "\n",
    "# df_all_threshold_x = compute_metrics_ex_1_2(random_states, percentiles, children_all, adults_all, image_names_c, image_names_a, sim_mat_c, sim_mat_a, num_ids_c, num_ids_a, ids_c, ids_a, balance_child_data, balance_adults_data_enrolled, compute_fnir, compute_fpir, GARBE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def plot_threshold_metrics_ex_1_2_w_conf(df_all_threshold_x, title,save_fig_path):\n",
    "#     # Set the aesthetics for the plots\n",
    "#     sns.set(style=\"whitegrid\")\n",
    "\n",
    "#     plot_df_mean = df_all_threshold_x.groupby('Threshold').mean()\n",
    "#     plot_df_std = df_all_threshold_x.groupby('Threshold').std()\n",
    "#     count = df_all_threshold_x.groupby('Threshold').size().values\n",
    "\n",
    "#     # Calculate the 95% confidence intervals\n",
    "#     ci_factor = 1.96\n",
    "#     plot_df_ci = plot_df_std / np.sqrt(count[:, None]) * ci_factor\n",
    "\n",
    "#     plt.figure(figsize=(12, 7))\n",
    "\n",
    "#     # Plot FNIR with confidence intervals\n",
    "#     plt.plot(plot_df_mean.index, plot_df_mean['FNIR_c'], color='#FBC02D', linestyle='-', label='Canonical - children - FNIR', linewidth=2.7)\n",
    "#     plt.fill_between(plot_df_mean.index, plot_df_mean['FNIR_c'] - plot_df_ci['FNIR_c'], plot_df_mean['FNIR_c'] + plot_df_ci['FNIR_c'], color='#FBC02D', alpha=0.2)\n",
    "#     plt.plot(plot_df_mean.index, plot_df_mean['FNIR_a'], color='#88E288', linestyle='-', label='Mixed quality - children - FNIR', linewidth=2.7)\n",
    "#     plt.fill_between(plot_df_mean.index, plot_df_mean['FNIR_a'] - plot_df_ci['FNIR_a'], plot_df_mean['FNIR_a'] + plot_df_ci['FNIR_a'], color='#88E288', alpha=0.2)\n",
    "\n",
    "#     plt.xlabel('Threshold', fontsize=14)\n",
    "#     plt.ylabel('FNIR and FPIR', fontsize=14)\n",
    "#     plt.title('FNIR vs Threshold', fontsize=16)\n",
    "#     plt.xlim(0.0, 1)\n",
    "#     plt.legend(fontsize=16)\n",
    "#     plt.grid(True)\n",
    "\n",
    "#     # Plot FPIR with confidence intervals\n",
    "#     plt.plot(plot_df_mean.index, plot_df_mean['FPIR_c'], color='#FBC02D', linestyle='--', label='Canonical - children - FPIR', linewidth=2.7)\n",
    "#     plt.fill_between(plot_df_mean.index, plot_df_mean['FPIR_c'] - plot_df_ci['FPIR_c'], plot_df_mean['FPIR_c'] + plot_df_ci['FPIR_c'], color='#FBC02D', alpha=0.2)\n",
    "#     plt.plot(plot_df_mean.index, plot_df_mean['FPIR_a'], color='#88E288', linestyle='--', label='Mixed quality - children - FPIR', linewidth=2.7)\n",
    "#     plt.fill_between(plot_df_mean.index, plot_df_mean['FPIR_a'] - plot_df_ci['FPIR_a'], plot_df_mean['FPIR_a'] + plot_df_ci['FPIR_a'], color='#88E288', alpha=0.2)\n",
    "\n",
    "#     plt.xlabel('Threshold', fontsize=14)\n",
    "#     plt.ylabel('FPIR and FNIR', fontsize=14)\n",
    "#     plt.title('FPIR and FNIR vs Threshold', fontsize=16)\n",
    "#     plt.xlim(0.0, 1)\n",
    "#     plt.legend(fontsize=16)\n",
    "#     plt.grid(True)\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.savefig(f'{save_fig_path}TH.png')\n",
    "\n",
    "#     # Show the plot\n",
    "#     plt.show()\n",
    "\n",
    "# plot_threshold_metrics_ex_1_2_w_conf(df_all_threshold_x, 'AdaFace ex. 1.2', save_fig_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stats - 10 experiments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPD result:  0.0\n",
      "FND result:  0.31368595107983305\n",
      "GARBE result, GARBE close to 1 means more unfair:  0.23526446330987477\n",
      "done\n",
      "FPD result:  0.0\n",
      "FND result:  0.28460854751499887\n",
      "GARBE result, GARBE close to 1 means more unfair:  0.21345641063624915\n",
      "done\n",
      "FPD result:  0.011283772379801887\n",
      "FND result:  0.28884475562138145\n",
      "GARBE result, GARBE close to 1 means more unfair:  0.21945450981098658\n",
      "done\n",
      "FPD result:  0.0\n",
      "FND result:  0.32383804244192355\n",
      "GARBE result, GARBE close to 1 means more unfair:  0.24287853183144265\n",
      "done\n",
      "FPD result:  0.011910224529241334\n",
      "FND result:  0.3685940993380387\n",
      "GARBE result, GARBE close to 1 means more unfair:  0.27942313063583935\n",
      "done\n",
      "FPD result:  0.0\n",
      "FND result:  0.31182749566679824\n",
      "GARBE result, GARBE close to 1 means more unfair:  0.23387062175009868\n",
      "done\n",
      "FPD result:  0.010816425084073406\n",
      "FND result:  0.26779386650497583\n",
      "GARBE result, GARBE close to 1 means more unfair:  0.20354950614975023\n",
      "done\n",
      "FPD result:  0.0192395206945734\n",
      "FND result:  0.33589820584040236\n",
      "GARBE result, GARBE close to 1 means more unfair:  0.25673353455394515\n",
      "done\n",
      "FPD result:  0.0\n",
      "FND result:  0.31736262594785497\n",
      "GARBE result, GARBE close to 1 means more unfair:  0.23802196946089121\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "random_states = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "\n",
    "df_all_results, sim_mat_dict_all_magface_ex1_2 = evaluate_metrics_ex_1_2(\n",
    "    random_states, children_all, adults_all, image_names_c, image_names_a,\n",
    "    sim_mat_c, sim_mat_a, num_ids_c, num_ids_a, ids_c, ids_a, balance_child_data,\n",
    "    balance_adults_data_enrolled, compute_fnir, compute_fpir, GARBE, remove_ones, 0.270#df_all_threshold_x[df_all_threshold_x.FNIR_a <0.05].Threshold.max()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the LaTeX table\n",
    "latex_table = generate_latex_table(df_all_results.applymap(lambda x: f\"{x:.3f}\").drop(columns='Iteration'))\n",
    "print(latex_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_table = generate_latex_table(df_all_results.describe().applymap(lambda x: f\"{x:.3f}\").drop(columns='Iteration'))\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_results.to_csv('df_all_results_ada_1_2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "t_statistic, p_value = stats.ttest_rel(df_all_results['FNIR_c'], df_all_results['FNIR_a'])\n",
    "\n",
    "# Output the results\n",
    "print(f'T-statistic: {t_statistic}')\n",
    "print(f'P-value: {p_value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gemmer simscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_results.to_csv('results_10_experiment_1_2_adaface.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add together all\n",
    "\n",
    "# make one  big array out of all arays named f'sim_mat_dict_all_magface_ex1_1['sim_mat_c_enrolled_iteration_{i}']' for i from 1 to 10\n",
    "# List to hold all the arrays\n",
    "sim_mat_c_enrolled_iterations = []\n",
    "\n",
    "# Loop to access each array and append it to the list\n",
    "for i in range(1, 11):\n",
    "    key = f'sim_mat_c_enrolled_iteration_{i}'\n",
    "    if key in sim_mat_dict_all_magface_ex1_2:\n",
    "        sim_mat_c_enrolled_iterations.append(sim_mat_dict_all_magface_ex1_2[key])\n",
    "\n",
    "# Concatenate all arrays into one big array\n",
    "sim_mat_c_enrolled_iterations_all = np.concatenate(sim_mat_c_enrolled_iterations)\n",
    "sim_mat_c_enrolled_iterations_all = pd.DataFrame(sim_mat_c_enrolled_iterations_all)\n",
    "sim_mat_c_enrolled_iterations_all.to_csv('sim_mat_c_enrolled_iterations_all_ada_1_2.csv', index=False)\n",
    "# Print the big array\n",
    "print(len(sim_mat_c_enrolled_iterations_all))\n",
    "\n",
    "\n",
    "\n",
    "# Add together all\n",
    "\n",
    "# make one  big array out of all arays named f'sim_mat_dict_all_magface_ex1_1['sim_mat_c_enrolled_iteration_{i}']' for i from 1 to 10\n",
    "\n",
    "# List to hold all the arrays\n",
    "sim_mat_a_enrolled_iterations = []\n",
    "\n",
    "# Loop to access each array and append it to the list\n",
    "for i in range(1, 11):\n",
    "    key = f'sim_mat_a_enrolled_iteration_{i}'\n",
    "    if key in sim_mat_dict_all_magface_ex1_2:\n",
    "        sim_mat_a_enrolled_iterations.append(sim_mat_dict_all_magface_ex1_2[key])\n",
    "\n",
    "# Concatenate all arrays into one big array\n",
    "sim_mat_a_enrolled_iterations_all = np.concatenate(sim_mat_a_enrolled_iterations)\n",
    "sim_mat_a_enrolled_iterations_all = pd.DataFrame(sim_mat_a_enrolled_iterations_all)\n",
    "sim_mat_a_enrolled_iterations_all.to_csv('sim_mat_a_enrolled_iterations_all_ada_1_2.csv', index=False)\n",
    "\n",
    "\n",
    "# Print the big array\n",
    "print(len(sim_mat_a_enrolled_iterations_all))\n",
    "\n",
    "# Add together all\n",
    "\n",
    "# make one  big array out of all arays named f'sim_mat_dict_all_magface_ex1_1['sim_mat_c_enrolled_iteration_{i}']' for i from 1 to 10\n",
    "\n",
    "# List to hold all the arrays\n",
    "sim_mat_c_non_enrolled_iterations = []\n",
    "\n",
    "# Loop to access each array and append it to the list\n",
    "for i in range(1, 11):\n",
    "    key = f'sim_mat_c_non_enrolled_iteration_{i}'\n",
    "    if key in sim_mat_dict_all_magface_ex1_2:\n",
    "        sim_mat_c_non_enrolled_iterations.append(sim_mat_dict_all_magface_ex1_2[key])\n",
    "\n",
    "sim_mat_c_non_enrolled_iterations_all = np.concatenate(sim_mat_c_non_enrolled_iterations)\n",
    "sim_mat_c_non_enrolled_iterations_all = pd.DataFrame(sim_mat_c_non_enrolled_iterations_all)\n",
    "sim_mat_c_non_enrolled_iterations_all.to_csv('sim_mat_c_non_enrolled_iterations_all_ada_1_2.csv', index=False)\n",
    "# Print the big array\n",
    "print(len(sim_mat_c_non_enrolled_iterations_all))\n",
    "\n",
    "\n",
    "# Add together all\n",
    "\n",
    "# make one  big array out of all arays named f'sim_mat_dict_all_magface_ex1_1['sim_mat_c_enrolled_iteration_{i}']' for i from 1 to 10\n",
    "\n",
    "# List to hold all the arrays\n",
    "sim_mat_a_non_enrolled_iterations = []\n",
    "\n",
    "# Loop to access each array and append it to the list\n",
    "for i in range(1, 11):\n",
    "    key = f'sim_mat_a_non_enrolled_iteration_{i}'\n",
    "    if key in sim_mat_dict_all_magface_ex1_2:\n",
    "        sim_mat_a_non_enrolled_iterations.append(sim_mat_dict_all_magface_ex1_2[key])\n",
    "\n",
    "sim_mat_a_non_enrolled_iterations_all = np.concatenate(sim_mat_a_non_enrolled_iterations)\n",
    "sim_mat_a_non_enrolled_iterations_all = pd.DataFrame(sim_mat_a_non_enrolled_iterations_all)\n",
    "sim_mat_a_non_enrolled_iterations_all.to_csv('sim_mat_a_non_enrolled_iterations_all_ada_1_2.csv', index=False)\n",
    "\n",
    "# Print the big array\n",
    "print(len(sim_mat_a_non_enrolled_iterations_all))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load sim scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Loading pre-saved stuff\n",
    "sim_mat_c_enrolled_iterations_all = (pd.read_csv('sim_mat_c_enrolled_iterations_all_ada_1_2.csv')).values.flatten()\n",
    "sim_mat_a_enrolled_iterations_all = (pd.read_csv('sim_mat_a_enrolled_iterations_all_ada_1_2.csv')).values.flatten()\n",
    "sim_mat_c_non_enrolled_iterations_all = (pd.read_csv('sim_mat_c_non_enrolled_iterations_all_ada_1_2.csv')).values.flatten()\n",
    "sim_mat_a_non_enrolled_iterations_all = (pd.read_csv('sim_mat_a_non_enrolled_iterations_all_ada_1_2.csv')).values.flatten()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From DET utils - check import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import describe, gaussian_kde\n",
    "import math\n",
    "\n",
    "def descriptive_statistics(mated_scores, nonmated_scores):\n",
    "    stats_labels = [\"Observations\", \"Minimum\", \"Maximum\", \"Mean\", \"St. Dev.\", \"Skewness\", \"Ex. Kurtosis\"]\n",
    "    mated_stats = describe(mated_scores)\n",
    "    mated_stats = [mated_stats.nobs, mated_stats.minmax[0], mated_stats.minmax[1], mated_stats.mean, math.sqrt(mated_stats.variance), mated_stats.skewness, mated_stats.kurtosis]\n",
    "    nonmated_stats = describe(nonmated_scores)\n",
    "    nonmated_stats = [nonmated_stats.nobs, nonmated_stats.minmax[0], nonmated_stats.minmax[1], nonmated_stats.mean, math.sqrt(nonmated_stats.variance), nonmated_stats.skewness, nonmated_stats.kurtosis]\n",
    "\n",
    "    stats_system_df = pd.DataFrame(np.array([stats_labels, mated_stats, nonmated_stats]).T, columns=[\"Statistic\", \"Mated\", \"Non-mated\"])\n",
    "    stats_system_df = stats_system_df.astype({\"Statistic\": str, \"Mated\": float, \"Non-mated\": float})\n",
    "    return stats_system_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mated_scores1 = sim_mat_a_enrolled_iterations_all\n",
    "nonmated_scores1 = sim_mat_a_non_enrolled_iterations_all\n",
    "scores_type1 = \"similarity\"\n",
    "stats_system1_df = descriptive_statistics(mated_scores1, nonmated_scores1)\n",
    "display(stats_system1_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mated_scores2 = sim_mat_c_enrolled_iterations_all\n",
    "\n",
    "nonmated_scores2 = sim_mat_c_non_enrolled_iterations_all\n",
    "scores_type2 = \"similarity\"\n",
    "stats_system2_df = descriptive_statistics(mated_scores2, nonmated_scores2)\n",
    "display(stats_system2_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mated_colour = \"green\"\n",
    "mated_label = \"Mated scores\"\n",
    "nonmated_colour = \"red\"\n",
    "nonmated_label = \"Non-mated scores\"\n",
    "\n",
    "figure_size = (12,6)\n",
    "alpha_shade = 0.25\n",
    "alpha_fill = 1.0\n",
    "linewidth = 2\n",
    "legend_loc = \"upper left\"\n",
    "legend_anchor = (1.0, 1.02)\n",
    "legend_cols = 1\n",
    "legend_fontsize = 12\n",
    "label_fontsize = 16\n",
    "\n",
    "threshold_colour = \"black\"\n",
    "threshold_style = \"--\"\n",
    "round_digits = 5\n",
    "sns.set(style=\"white\", palette=\"muted\", color_codes=True)\n",
    "plt.rc(\"axes\", axisbelow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_histogram(mated_scores, nonmated_scores, normalise=True, savename=None, title=\"Histogram\", save_fig_path=\"save_fig_path\", gem_som = 'A1'):\n",
    "    def normalise_scores(distribution):\n",
    "        return np.ones_like(distribution) / len(distribution)\n",
    "\n",
    "    mated_mean = np.mean(mated_scores)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    if normalise:\n",
    "        plt.hist(mated_scores, bins=50, weights=normalise_scores(mated_scores), color='green', alpha=0.5, label='Mated Scores')\n",
    "        plt.hist(nonmated_scores, bins=30, weights=normalise_scores(nonmated_scores), color='red', alpha=0.5, label='Non-mated Scores')\n",
    "        ylabel = \"Probability Density\"\n",
    "    else:\n",
    "        plt.hist(mated_scores, bins=50, color='green', alpha=0.5, label='Mated Scores')\n",
    "        plt.hist(nonmated_scores, bins=30, color='red', alpha=0.5, label='Non-mated Scores')\n",
    "        ylabel = \"Count\"\n",
    "\n",
    "    plt.axvline(mated_mean, color='darkgreen', linestyle='--', linewidth=2, label=f'Mated Mean: {mated_mean:.2f}')\n",
    "\n",
    "    plt.xlabel(\"Comparison Score\", size=16)\n",
    "    plt.ylabel(ylabel, size=16)\n",
    "    plt.title(title, size=20)\n",
    "    plt.grid(True)\n",
    "    plt.legend(loc='upper right', bbox_to_anchor=(1, 1), ncol=1, fontsize=14)  # Adjust legend parameters as needed\n",
    "\n",
    "    plt.savefig(f'{save_fig_path}{gem_som}.png')\n",
    "\n",
    "    plt.show()\n",
    "plot_histogram(mated_scores1, nonmated_scores1, normalise=True, title = 'Mixed-quality children - AdaFace ex. 1.2 ', save_fig_path=save_fig_path, gem_som = 'M1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram(mated_scores2, nonmated_scores2, normalise=True,title = 'Canonical children - AdaFace ex. 1.2 ', save_fig_path=save_fig_path, gem_som = 'Can1')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DET CURVES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mated_kde, mated_pos, mated_min, mated_max = get_kde(mated_scores1)\n",
    "nonmated_kde, nonmated_pos, nonmated_min, nonmated_max = get_kde(nonmated_scores1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_prime_system1 = d_prime(mated_scores1, nonmated_scores1)\n",
    "print(\"d' mixed =\", round(d_prime_system1, round_digits))\n",
    "\n",
    "d_prime_system2 = d_prime(mated_scores2, nonmated_scores2)\n",
    "print(\"d' canonical =\", round(d_prime_system2, round_digits))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold1 = df_all_threshold_x[df_all_threshold_x.FNIR_a <0.05].Threshold.max()\n",
    "kde_with_threshold(mated_scores1, nonmated_scores1, scores_type1, threshold1, save_fig_path=save_fig_path, title='M2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold2 = df_all_threshold_x[df_all_threshold_x.FNIR_a <0.05].Threshold.max()\n",
    "kde_with_threshold(mated_scores2, nonmated_scores2, scores_type2, threshold2,save_fig_path=save_fig_path, title='Can2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DET_plotting_1_2(mated_scores1, mated_scores2,nonmated_scores1, nonmated_scores2, score_type= \"similarity\",title = 'Canonical vs Mixed-quality - AdaFace ex. 2.2', save_fig_path= 'save_fig_path'):\n",
    "\n",
    "    figure_size = (12,7)\n",
    "    alpha_shade = 0.25\n",
    "    alpha_fill = 1.0\n",
    "    linewidth = 2\n",
    "    legend_loc = \"upper left\"\n",
    "    legend_anchor = (1.0, 1.02)\n",
    "    legend_cols = 1\n",
    "    legend_fontsize = 18\n",
    "    label_fontsize = 18\n",
    "    tick_fontsize = 18\n",
    "\n",
    "    system_name1 = 'Mixed quality - children'\n",
    "    system_name2 = 'Canonical - children'\n",
    "\n",
    "    det = DET(biometric_evaluation_type='identification', abbreviate_axes=True, plot_eer_line=True, plot_title=title)\n",
    "    det.x_limits = np.array([1e-5, .8])\n",
    "    det.y_limits = np.array([1e-5, .8])\n",
    "    det.x_ticks = np.array([1e-4, 1e-3, 1e-2, 5e-2, 20e-2, 40e-2, 80e-2])\n",
    "    det.x_ticklabels = np.array(['0.01','0.1', '1', '5', '20', '40', '80'])\n",
    "    det.y_ticks = np.array([1e-4, 1e-3, 1e-2, 5e-2, 20e-2, 40e-2, 80e-2])\n",
    "    det.y_ticklabels = np.array(['0.01','0.1', '1', '5', '20', '40', '80'])\n",
    "    det.create_figure()\n",
    "    det.plot(tar=adjust_scores_for_DET(mated_scores1, score_type), non=adjust_scores_for_DET(nonmated_scores1, score_type), label=system_name1)\n",
    "    det.plot(tar=adjust_scores_for_DET(mated_scores2, score_type), non=adjust_scores_for_DET(nonmated_scores2, score_type), label=system_name2)\n",
    "    det.legend_on(loc=\"upper right\")\n",
    "    det.show()\n",
    "DET_plotting_1_2(mated_scores1, mated_scores2,nonmated_scores1, nonmated_scores2, \"similarity\",'Canonical vs Mixed-quality - AdaFace ex. 1.2', save_fig_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "best_master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
