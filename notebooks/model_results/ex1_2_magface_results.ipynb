{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPERIMENT 1: MagFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load libraries\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import normalize\n",
    "import sys\n",
    "sns.set(style=\"white\")\n",
    "%matplotlib inline\n",
    "sys.path.append('../../utils')\n",
    "from Model_utils.Model_funcs import *\n",
    "from Result_metric_utils.result_metrics import *\n",
    "from Data_proc_utils.Data_proc_funcs import *\n",
    "\n",
    "from IPython import embed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MagFace Results\n",
    "\n",
    "This notebook loads the feature vectors from MagFace and run them through the results metrics:\n",
    "FNIR, FPIR, FND, FPD, and GARBE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list_children = '../../data/data_full/feature_vectors/magface_feature_vectors/feat_img_children_full.list'\n",
    "# feature_list_adults = '../../data/data_full/feature_vectors/magface_feature_vectors/feat_img_children_full.list'\n",
    "\n",
    "\n",
    "def load_and_compute_similarity(feature_list, dtype=np.float32):\n",
    "    # Load data\n",
    "    image_names, ids, num_ids, norm_feats = load_magface_vectors(feature_list)\n",
    "\n",
    "    # Convert dtype to reduce memory usage\n",
    "    norm_feats = norm_feats.astype(dtype)\n",
    "\n",
    "    # Compute similarity matrix incrementally if possible\n",
    "    sim_mat = np.dot(norm_feats, norm_feats.T)\n",
    "\n",
    "    return image_names, ids, num_ids, sim_mat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and compute for children\n",
    "image_names_c, ids_c, num_ids_c, sim_mat_c = load_and_compute_similarity(feature_list_children)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load and compute for adults\n",
    "image_names_a, ids_a, num_ids_a, sim_mat_a = load_and_compute_similarity(feature_list_children)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Dataframes with info, removes names not in magface results\n",
    "children_all = pd.read_csv('../../data/image_info_csvs/final_filtered_canonical_df_BIBLE.csv')\n",
    "children_all = children_all[children_all.image_name.isin(image_names_c)]\n",
    "\n",
    "adults_all_org = pd.read_csv('../../data/image_info_csvs/final_filtered_children_df_BIBEL.csv')\n",
    "adults_all = adults_all_org[adults_all_org.image_name.isin(image_names_a)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her = 584\n",
    "print(image_names_c[her], ids_c[her], num_ids_c[her])\n",
    "print(image_names_a[her], ids_a[her], num_ids_a[her])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GET METRICS 10 TIMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_child_data_can(y_df, print_stats=False, random_state=42):\n",
    "    \"\"\"\n",
    "    Input: raw df for ylfw and rfw\n",
    "    Returns: csvs with equally balanced children and adults\n",
    "    Original child_balanced has random state 42\n",
    "    \"\"\"\n",
    "\n",
    "    # Randomly sample 1000 identities from the entire dataset\n",
    "    ylfw_witha_balanced = y_df.sample(n=2000, random_state=random_state)\n",
    "\n",
    "    if print_stats:\n",
    "        # Print the distribution of age groups and other relevant statistics\n",
    "        print(\"Balanced data?:\", ylfw_witha_balanced.children_agegroup.value_counts())\n",
    "\n",
    "    return ylfw_witha_balanced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "random_states = [1,2,3,4,5,6,7,8,9,10]\n",
    "sim_mat_dict_all_magface_ex1_1 = {}\n",
    "FNIR_c_list=[]\n",
    "FNIR_a_list=[]\n",
    "FPIR_c_list=[]\n",
    "FPIR_a_list=[]\n",
    "FPD_list=[]\n",
    "FND_list=[]\n",
    "GARBE_list=[]\n",
    "threshold_list = []\n",
    "# percentile = 94\n",
    "\n",
    "for random_state_i in random_states:\n",
    "\n",
    "    ### Load children and adults balanced data ###\n",
    "    children_balanced_df_i = balance_child_data_can(children_all, print_stats=False, random_state=random_state_i)\n",
    "    adults_balanced_df_i = balance_child_data(adults_all, print_stats=False, random_state=random_state_i)\n",
    "\n",
    "\n",
    "    ### All reference image names, enrolled and non-enrolled image names - children ###\n",
    "    c_mates = children_balanced_df_i.groupby(\"identity_name\").agg({'identity_name': ['count']})\n",
    "    enrolled_identity_names_c = c_mates[c_mates[('identity_name', 'count')] > 1].index\n",
    "    enrolled_image_names_c = list(children_balanced_df_i[children_balanced_df_i[\"identity_name\"].isin(enrolled_identity_names_c)].image_name)\n",
    "    non_enrolled_identity_names_c = c_mates[c_mates[('identity_name', 'count')] == 1].index\n",
    "    non_enrolled_image_names_c = list(children_balanced_df_i[children_balanced_df_i[\"identity_name\"].isin(non_enrolled_identity_names_c)].image_name)\n",
    "    all_reference_image_names_c = list(children_balanced_df_i.image_name)\n",
    "\n",
    "\n",
    "    ### All reference image names, enrolled and non-enrolled image names - adults ###\n",
    "    a_mates = adults_balanced_df_i.groupby(\"identity_name\").agg({'identity_name': ['count']})\n",
    "    enrolled_identity_names_a = a_mates[a_mates[('identity_name', 'count')] > 1].index\n",
    "    enrolled_image_names_a = list(adults_balanced_df_i[adults_balanced_df_i[\"identity_name\"].isin(enrolled_identity_names_a)].image_name)\n",
    "    non_enrolled_identity_names_a = a_mates[a_mates[('identity_name', 'count')] == 1].index\n",
    "    non_enrolled_image_names_a = list(adults_balanced_df_i[adults_balanced_df_i[\"identity_name\"].isin(non_enrolled_identity_names_a)].image_name)\n",
    "    all_reference_image_names_a = list(adults_balanced_df_i.image_name)\n",
    "\n",
    "\n",
    "\n",
    "    ### Similarity matrices for ids in reference database ###\n",
    "    indices_c_all_reference = [image_names_c.index(name) for name in all_reference_image_names_c]\n",
    "    indices_a_all_reference = [image_names_a.index(name) for name in all_reference_image_names_a]\n",
    "\n",
    "\n",
    "\n",
    "    # Extract corresponding columns from the similarity matrix\n",
    "    sim_mat_c_reference_cols = sim_mat_c[:, indices_c_all_reference]\n",
    "\n",
    "\n",
    "    sim_mat_a_reference_cols = sim_mat_a[:, indices_a_all_reference]\n",
    "\n",
    "    # Extract corresponding rows from the numerical ids\n",
    "    num_ids_c_reference = num_ids_c[indices_c_all_reference]\n",
    "    num_ids_a_reference = num_ids_a[indices_a_all_reference]\n",
    "\n",
    "\n",
    "    ### Similarity matrices for non-enrolled ids ###\n",
    "    # Get indices of all feature and numerical id elements that are non-enrolled  ids\n",
    "    indices_c_non_enrolled = [image_names_c.index(name) for name in non_enrolled_image_names_c]\n",
    "    indices_a_non_enrolled = [image_names_a.index(name) for name in non_enrolled_image_names_a]\n",
    "\n",
    "\n",
    "    # Extract corresponding rows from the similarity matrix\n",
    "    sim_mat_c_non_enrolled_0 = sim_mat_c_reference_cols[indices_c_non_enrolled]\n",
    "    sim_mat_a_non_enrolled_0 = sim_mat_a_reference_cols[indices_a_non_enrolled]\n",
    "\n",
    "    # Extract corresponding rows from the numerical ids\n",
    "    num_ids_c_non_enrolled = num_ids_c[indices_c_non_enrolled]\n",
    "    num_ids_a_non_enrolled = num_ids_a[indices_a_non_enrolled]\n",
    "\n",
    "\n",
    "    ### Similarity matrices for enrolled ids ###\n",
    "    # Get indices of all feature and numerical id elements that are enrolled ids\n",
    "    indices_c_enrolled = [image_names_c.index(name) for name in enrolled_image_names_c]\n",
    "    indices_a_enrolled = [image_names_a.index(name) for name in enrolled_image_names_a]\n",
    "\n",
    "    # Extract corresponding rows from the similarity matrix\n",
    "    sim_mat_c_enrolled_0 = sim_mat_c[np.ix_(indices_c_enrolled, indices_c_enrolled)] # only enrolled columns and rows\n",
    "    sim_mat_a_enrolled_0 = sim_mat_a[np.ix_(indices_a_enrolled, indices_a_enrolled)]\n",
    "\n",
    "    # Extract corresponding rows from the numerical ids\n",
    "    num_ids_c_enrolled = num_ids_c[indices_c_enrolled]\n",
    "    num_ids_a_enrolled = num_ids_a[indices_a_enrolled]\n",
    "\n",
    "\n",
    "    ### DET THINGS ###\n",
    "\n",
    "    # thold = (np.percentile(sim_mat_c,90)+np.percentile(sim_mat_a,90))/2\n",
    "    # thold = ((np.percentile(sim_mat_c_non_enrolled_0,90) + (np.percentile(sim_mat_a_non_enrolled_0,90)))/2 + (np.percentile(sim_mat_c_enrolled_0,90) + (np.percentile(sim_mat_a_enrolled_0,90)))/2 )/2\n",
    "    # thold = np.percentile(sim_mat_a, 99)\n",
    "    thold = 0.31\n",
    "    # thold = (np.percentile(sim_mat_c,percentile)+np.percentile(sim_mat_a,percentile))/2\n",
    "\n",
    "    ### Evaluation metrics ###\n",
    "    # FNIR\n",
    "    FNIR_c, sim_mat_c_enrolled = compute_fnir(sim_mat_c_enrolled_0, sim_mat_c, enrolled_identity_names_c, num_ids_c_enrolled, ids_c, thold=thold)\n",
    "    FNIR_a, sim_mat_a_enrolled = compute_fnir(sim_mat_a_enrolled_0, sim_mat_a, enrolled_identity_names_a, num_ids_a_enrolled, ids_a, thold=thold)\n",
    "    # FPIR\n",
    "    FPIR_c = compute_fpir(sim_mat_c_non_enrolled_0, num_ids_c_non_enrolled, num_ids_c_reference, thold=thold)\n",
    "    FPIR_a = compute_fpir(sim_mat_a_non_enrolled_0, num_ids_a_non_enrolled, num_ids_a_reference, thold=thold)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # OBS maybe compute Garbe outside funtion to choose a good alpha?\n",
    "    alpha_garbe = 0.25\n",
    "    FPD_i, FND_i, GARBE_i = GARBE(FNIR_c, FNIR_a, FPIR_c, FPIR_a, alpha=alpha_garbe)\n",
    "\n",
    "\n",
    "    FNIR_c_list.append(FNIR_c)\n",
    "    FNIR_a_list.append(FNIR_a)\n",
    "    FPIR_c_list.append(FPIR_c)\n",
    "    FPIR_a_list.append(FPIR_a)\n",
    "    FPD_list.append(FPD_i)\n",
    "    FND_list.append(FND_i)\n",
    "    GARBE_list.append(GARBE_i)\n",
    "    threshold_list.append(thold)\n",
    "\n",
    "    sim_mat_dict_all_magface_ex1_1['sim_mat_c_enrolled_iteration_{}'.format(random_state_i)]=sim_mat_c_enrolled\n",
    "    sim_mat_dict_all_magface_ex1_1['sim_mat_a_enrolled_iteration_{}'.format(random_state_i)]=sim_mat_a_enrolled\n",
    "    sim_mat_dict_all_magface_ex1_1['sim_mat_c_non_enrolled_iteration_{}'.format(random_state_i)]=remove_ones(sim_mat_c_non_enrolled_0)\n",
    "    sim_mat_dict_all_magface_ex1_1['sim_mat_a_non_enrolled_iteration_{}'.format(random_state_i)]=remove_ones(sim_mat_a_non_enrolled_0)\n",
    "\n",
    "\n",
    "    print(\"done\")\n",
    "\n",
    "data = {\n",
    "    'Iteration': random_states,\n",
    "    'FNIR_c': FNIR_c_list,\n",
    "    'FNIR_a': FNIR_a_list,\n",
    "    'FPIR_c': FPIR_c_list,\n",
    "    'FPIR_a': FPIR_a_list,\n",
    "    'FPD': FPD_list,\n",
    "    'FND': FND_list,\n",
    "    'GARBE': GARBE_list,\n",
    "    'Threshold': threshold_list\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_results = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_threshold_84 = pd.DataFrame(data)\n",
    "data_threshold_plot = pd.concat([data_threshold_plot, df_all_threshold_84 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_threshold_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_threshold_plot.sort_values(by = 'Threshold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by threshold\n",
    "plot_df = data_threshold_plot.groupby('Threshold').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df.to_csv('magface_1_2_threshold_FNIR_plot.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting FNIR and FPIR vs. Threshold\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "# Plot FNIR\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(plot_df.index, plot_df['FNIR_c'], 'r-', label='Canonical - children')\n",
    "plt.plot(plot_df.index, plot_df['FNIR_a'], 'c-', label='Mixed quality - children')\n",
    "# plt.yscale('log')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('FNIR')\n",
    "plt.title('FNIR vs Threshold')\n",
    "plt.legend()\n",
    "\n",
    "# Plot FPIR\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(plot_df.index, plot_df['FPIR_c'], 'r-', label='Canonical - children')\n",
    "plt.plot(plot_df.index, plot_df['FPIR_a'], 'c-', label='Mixed quality - children')\n",
    "# plt.yscale('log')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('FPIR')\n",
    "plt.title('FPIR vs Threshold')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_results.describe().applymap(lambda x: f\"{x:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving sim to plot all of the dist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add together all\n",
    "\n",
    "# make one  big array out of all arays named f'sim_mat_dict_all_magface_ex1_1['sim_mat_c_enrolled_iteration_{i}']' for i from 1 to 10\n",
    "# List to hold all the arrays\n",
    "sim_mat_c_enrolled_iterations = []\n",
    "\n",
    "# Loop to access each array and append it to the list\n",
    "for i in range(1, 11):\n",
    "    key = f'sim_mat_c_enrolled_iteration_{i}'\n",
    "    if key in sim_mat_dict_all_magface_ex1_1:\n",
    "        sim_mat_c_enrolled_iterations.append(sim_mat_dict_all_magface_ex1_1[key])\n",
    "\n",
    "# Concatenate all arrays into one big array\n",
    "sim_mat_c_enrolled_iterations_all = np.concatenate(sim_mat_c_enrolled_iterations)\n",
    "sim_mat_c_enrolled_iterations_all = pd.DataFrame(sim_mat_c_enrolled_iterations_all)\n",
    "sim_mat_c_enrolled_iterations_all.to_csv('sim_mat_c_enrolled_iterations_all_mag_1_2.csv', index=False)\n",
    "# Print the big array\n",
    "print(len(sim_mat_c_enrolled_iterations_all))\n",
    "\n",
    "\n",
    "\n",
    "# Add together all\n",
    "\n",
    "# make one  big array out of all arays named f'sim_mat_dict_all_magface_ex1_1['sim_mat_c_enrolled_iteration_{i}']' for i from 1 to 10\n",
    "\n",
    "# List to hold all the arrays\n",
    "sim_mat_a_enrolled_iterations = []\n",
    "\n",
    "# Loop to access each array and append it to the list\n",
    "for i in range(1, 11):\n",
    "    key = f'sim_mat_a_enrolled_iteration_{i}'\n",
    "    if key in sim_mat_dict_all_magface_ex1_1:\n",
    "        sim_mat_a_enrolled_iterations.append(sim_mat_dict_all_magface_ex1_1[key])\n",
    "\n",
    "# Concatenate all arrays into one big array\n",
    "sim_mat_a_enrolled_iterations_all = np.concatenate(sim_mat_a_enrolled_iterations)\n",
    "sim_mat_a_enrolled_iterations_all = pd.DataFrame(sim_mat_a_enrolled_iterations_all)\n",
    "sim_mat_a_enrolled_iterations_all.to_csv('sim_mat_a_enrolled_iterations_all_mag_1_2.csv', index=False)\n",
    "\n",
    "\n",
    "# Print the big array\n",
    "print(len(sim_mat_a_enrolled_iterations_all))\n",
    "\n",
    "# Add together all\n",
    "\n",
    "# make one  big array out of all arays named f'sim_mat_dict_all_magface_ex1_1['sim_mat_c_enrolled_iteration_{i}']' for i from 1 to 10\n",
    "\n",
    "# List to hold all the arrays\n",
    "sim_mat_c_non_enrolled_iterations = []\n",
    "\n",
    "# Loop to access each array and append it to the list\n",
    "for i in range(1, 11):\n",
    "    key = f'sim_mat_c_non_enrolled_iteration_{i}'\n",
    "    if key in sim_mat_dict_all_magface_ex1_1:\n",
    "        sim_mat_c_non_enrolled_iterations.append(sim_mat_dict_all_magface_ex1_1[key])\n",
    "\n",
    "sim_mat_c_non_enrolled_iterations_all = np.concatenate(sim_mat_c_non_enrolled_iterations)\n",
    "sim_mat_c_non_enrolled_iterations_all = pd.DataFrame(sim_mat_c_non_enrolled_iterations_all)\n",
    "sim_mat_c_non_enrolled_iterations_all.to_csv('sim_mat_c_non_enrolled_iterations_all_mag_1_2.csv', index=False)\n",
    "# Print the big array\n",
    "print(len(sim_mat_c_non_enrolled_iterations_all))\n",
    "\n",
    "\n",
    "# Add together all\n",
    "\n",
    "# make one  big array out of all arays named f'sim_mat_dict_all_magface_ex1_1['sim_mat_c_enrolled_iteration_{i}']' for i from 1 to 10\n",
    "\n",
    "# List to hold all the arrays\n",
    "sim_mat_a_non_enrolled_iterations = []\n",
    "\n",
    "# Loop to access each array and append it to the list\n",
    "for i in range(1, 11):\n",
    "    key = f'sim_mat_a_non_enrolled_iteration_{i}'\n",
    "    if key in sim_mat_dict_all_magface_ex1_1:\n",
    "        sim_mat_a_non_enrolled_iterations.append(sim_mat_dict_all_magface_ex1_1[key])\n",
    "\n",
    "sim_mat_a_non_enrolled_iterations_all = np.concatenate(sim_mat_a_non_enrolled_iterations)\n",
    "sim_mat_a_non_enrolled_iterations_all = pd.DataFrame(sim_mat_a_non_enrolled_iterations_all)\n",
    "sim_mat_a_non_enrolled_iterations_all.to_csv('sim_mat_a_non_enrolled_iterations_all_mag_1_2.csv', index=False)\n",
    "\n",
    "# Print the big array\n",
    "print(len(sim_mat_a_non_enrolled_iterations_all))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Loading pre-saved stuff\n",
    "sim_mat_c_enrolled_iterations_all = (pd.read_csv('sim_mat_c_enrolled_iterations_all_mag_1_2.csv')).values.flatten()\n",
    "sim_mat_a_enrolled_iterations_all = (pd.read_csv('sim_mat_a_enrolled_iterations_all_mag_1_2.csv')).values.flatten()\n",
    "sim_mat_c_non_enrolled_iterations_all = (pd.read_csv('sim_mat_c_non_enrolled_iterations_all_mag_1_2.csv')).values.flatten()\n",
    "sim_mat_a_non_enrolled_iterations_all = (pd.read_csv('sim_mat_a_non_enrolled_iterations_all_mag_1_2.csv')).values.flatten()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From DET utils - check import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import describe, gaussian_kde\n",
    "import math\n",
    "\n",
    "def descriptive_statistics(mated_scores, nonmated_scores):\n",
    "    stats_labels = [\"Observations\", \"Minimum\", \"Maximum\", \"Mean\", \"St. Dev.\", \"Skewness\", \"Ex. Kurtosis\"]\n",
    "    mated_stats = describe(mated_scores)\n",
    "    mated_stats = [mated_stats.nobs, mated_stats.minmax[0], mated_stats.minmax[1], mated_stats.mean, math.sqrt(mated_stats.variance), mated_stats.skewness, mated_stats.kurtosis]\n",
    "    nonmated_stats = describe(nonmated_scores)\n",
    "    nonmated_stats = [nonmated_stats.nobs, nonmated_stats.minmax[0], nonmated_stats.minmax[1], nonmated_stats.mean, math.sqrt(nonmated_stats.variance), nonmated_stats.skewness, nonmated_stats.kurtosis]\n",
    "\n",
    "    stats_system_df = pd.DataFrame(np.array([stats_labels, mated_stats, nonmated_stats]).T, columns=[\"Statistic\", \"Mated\", \"Non-mated\"])\n",
    "    stats_system_df = stats_system_df.astype({\"Statistic\": str, \"Mated\": float, \"Non-mated\": float})\n",
    "    return stats_system_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mated_scores1 = sim_mat_a_enrolled_iterations_all\n",
    "nonmated_scores1 = sim_mat_a_non_enrolled_iterations_all\n",
    "scores_type1 = \"similarity\"\n",
    "stats_system1_df = descriptive_statistics(mated_scores1, nonmated_scores1)\n",
    "display(stats_system1_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mated_scores2 = sim_mat_c_enrolled_iterations_all\n",
    "\n",
    "nonmated_scores2 = sim_mat_c_non_enrolled_iterations_all\n",
    "scores_type2 = \"similarity\"\n",
    "stats_system2_df = descriptive_statistics(mated_scores2, nonmated_scores2)\n",
    "display(stats_system2_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mated_colour = \"green\"\n",
    "mated_label = \"Mated scores\"\n",
    "nonmated_colour = \"red\"\n",
    "nonmated_label = \"Non-mated scores\"\n",
    "\n",
    "figure_size = (12,6)\n",
    "alpha_shade = 0.25\n",
    "alpha_fill = 1.0\n",
    "linewidth = 2\n",
    "legend_loc = \"upper left\"\n",
    "legend_anchor = (1.0, 1.02)\n",
    "legend_cols = 1\n",
    "legend_fontsize = 12\n",
    "label_fontsize = 16\n",
    "\n",
    "threshold_colour = \"black\"\n",
    "threshold_style = \"--\"\n",
    "round_digits = 5\n",
    "sns.set(style=\"white\", palette=\"muted\", color_codes=True)\n",
    "plt.rc(\"axes\", axisbelow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_histogram(mated_scores, nonmated_scores, normalise=True, savename=None):\n",
    "#     def normalise_scores(distribution):\n",
    "#         return np.ones_like(distribution) / len(distribution)\n",
    "#     plt.figure(figsize=figure_size)\n",
    "#     if normalise:\n",
    "#         plt.hist(mated_scores, bins=50, weights=normalise_scores(mated_scores), color='red', alpha=0.5, label=mated_label)\n",
    "#         plt.hist(nonmated_scores, bins=30, weights=normalise_scores(nonmated_scores), color='green', alpha=0.5, label=nonmated_label)\n",
    "#         xlabel = \"Probability Density\"\n",
    "#     else:\n",
    "#         plt.hist(mated_scores, bins=50, color='red', alpha=0.5, label=mated_label)\n",
    "#         plt.hist(nonmated_scores, bins=30, color='green', alpha=0.5, label=nonmated_label)\n",
    "#         xlabel = \"Count\"\n",
    "#     plt.xlabel(\"Comparison Score\", size=label_fontsize)\n",
    "#     plt.ylabel(xlabel, size=label_fontsize)\n",
    "#     plt.grid(True)\n",
    "#     plt.legend(loc=legend_loc, bbox_to_anchor=legend_anchor, ncol=legend_cols, fontsize=legend_fontsize)\n",
    "\n",
    "#     if savename is not None:\n",
    "#         plt.savefig(savename, bbox_inches=\"tight\")\n",
    "#         plt.cla()\n",
    "#         plt.clf()\n",
    "#         plt.close()\n",
    "#     else:\n",
    "#         plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def plot_histogram(mated_scores, nonmated_scores, normalise=True, savename=None):\n",
    "    def normalise_scores(distribution):\n",
    "        return np.ones_like(distribution) / len(distribution)\n",
    "\n",
    "    mated_mean = np.mean(mated_scores)\n",
    "\n",
    "    plt.figure(figsize=figure_size)\n",
    "\n",
    "    if normalise:\n",
    "        plt.hist(mated_scores, bins=50, weights=normalise_scores(mated_scores), color='red', alpha=0.5, label=mated_label)\n",
    "        plt.hist(nonmated_scores, bins=30, weights=normalise_scores(nonmated_scores), color='green', alpha=0.5, label=nonmated_label)\n",
    "        ylabel = \"Probability Density\"\n",
    "    else:\n",
    "        plt.hist(mated_scores, bins=50, color='red', alpha=0.5, label=mated_label)\n",
    "        plt.hist(nonmated_scores, bins=30, color='green', alpha=0.5, label=nonmated_label)\n",
    "        ylabel = \"Count\"\n",
    "\n",
    "    plt.axvline(mated_mean, color='darkred', linestyle='--', linewidth=2, label=f'Mated Mean: {mated_mean:.2f}')\n",
    "\n",
    "    plt.xlabel(\"Comparison Score\", size=label_fontsize)\n",
    "    plt.ylabel(ylabel, size=label_fontsize)\n",
    "    plt.grid(True)\n",
    "    plt.legend(loc=legend_loc, bbox_to_anchor=legend_anchor, ncol=legend_cols, fontsize=legend_fontsize)\n",
    "\n",
    "    if savename is not None:\n",
    "        plt.savefig(savename, bbox_inches=\"tight\")\n",
    "        plt.cla()\n",
    "        plt.clf()\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_histogram(mated_scores1, nonmated_scores1, normalise=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram(mated_scores2, nonmated_scores2, normalise=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DET curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DET_utils.DET_plots import *\n",
    "from DET_utils.DET import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mated_kde, mated_pos, mated_min, mated_max = get_kde(mated_scores1)\n",
    "nonmated_kde, nonmated_pos, nonmated_min, nonmated_max = get_kde(nonmated_scores1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_prime_system1 = d_prime(mated_scores1, nonmated_scores1)\n",
    "print(\"d' child =\", round(d_prime_system1, round_digits))\n",
    "\n",
    "d_prime_system2 = d_prime(mated_scores2, nonmated_scores2)\n",
    "print(\"d' adult =\", round(d_prime_system2, round_digits))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold1 = 0.31\n",
    "kde_with_threshold(mated_scores1, nonmated_scores1, scores_type1, threshold1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold2 = 0.31\n",
    "kde_with_threshold(mated_scores2, nonmated_scores2, scores_type2, threshold2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_name1 = 'Mixed quality - children'\n",
    "system_name2 = 'Canonical - children'\n",
    "\n",
    "det = DET(biometric_evaluation_type='identification', abbreviate_axes=True, plot_eer_line=True, plot_title=\"Children vs adults\")\n",
    "det.x_limits = np.array([1e-4, .5])\n",
    "det.y_limits = np.array([1e-4, .5])\n",
    "det.x_ticks = np.array([1e-3, 1e-2, 5e-2, 20e-2, 40e-2])\n",
    "det.x_ticklabels = np.array(['0.1', '1', '5', '20', '40'])\n",
    "det.y_ticks = np.array([1e-3, 1e-2, 5e-2, 20e-2, 40e-2])\n",
    "det.y_ticklabels = np.array(['0.1', '1', '5', '20', '40'])\n",
    "det.create_figure()\n",
    "det.plot(tar=adjust_scores_for_DET(mated_scores1, scores_type1), non=adjust_scores_for_DET(nonmated_scores1, scores_type1), label=system_name1)\n",
    "det.plot(tar=adjust_scores_for_DET(mated_scores2, scores_type2), non=adjust_scores_for_DET(nonmated_scores2, scores_type2), label=system_name2)\n",
    "det.legend_on(loc=\"upper right\")\n",
    "det.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "best_master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
