{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporary MagFace dataloader \n",
    "\n",
    "source: https://github.com/IrvingMeng/MagFace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader\n",
    "Denne data loader er herfra: https://github.com/IrvingMeng/MagFace/blob/main/dataloader/dataloader.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from utils import cv2_trans_mag as transforms\n",
    "from termcolor import cprint\n",
    "import cv2\n",
    "import torchvision\n",
    "import torch.utils.data as data\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "\n",
    "class MagTrainDataset(data.Dataset):\n",
    "    def __init__(self, ann_file, transform=None):\n",
    "        self.ann_file = ann_file\n",
    "        self.transform = transform\n",
    "        self.init()\n",
    "\n",
    "    def init(self):\n",
    "        self.weight = {}\n",
    "        self.im_names = []\n",
    "        self.targets = []\n",
    "        self.pre_types = []\n",
    "        with open(self.ann_file) as f:\n",
    "            for line in f.readlines():\n",
    "                data = line.strip().split(' ')\n",
    "                self.im_names.append(data[0])\n",
    "                self.targets.append(int(data[2]))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        im_name = self.im_names[index]\n",
    "        target = self.targets[index]\n",
    "        img = cv2.imread(im_name)\n",
    "\n",
    "        img = self.transform(img)\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.im_names)\n",
    "\n",
    "\n",
    "def train_loader(args):\n",
    "    train_trans = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    train_dataset = MagTrainDataset(\n",
    "        args.train_list,\n",
    "        transform=train_trans\n",
    "    )\n",
    "    train_sampler = None\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        shuffle=(train_sampler is None),\n",
    "        batch_size=args.batch_size,\n",
    "        num_workers=args.workers,\n",
    "        pin_memory=True,\n",
    "        sampler=train_sampler,\n",
    "        drop_last=(train_sampler is None))\n",
    "\n",
    "    return train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# load data\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m train_loader(\u001b[43margs\u001b[49m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (\u001b[38;5;28minput\u001b[39m, target) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "\n",
    "train_loader = train_loader(args)\n",
    "for i, (input, target) in enumerate(train_loader):\n",
    "    print(input.size())\n",
    "    print(target.size())\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modellen \n",
    "Modeller befinder sig i Models folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training of the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'iresnet' from 'models' (/mnt/c/Dokumenter/Dokumenter/UNI/Master/Thesis/GitHub_Repo/Master_Thesis/notebooks/../models/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# from dataloader import dataloader\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m magface\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/c/Dokumenter/Dokumenter/UNI/Master/Thesis/GitHub_Repo/Master_Thesis/notebooks/../models/magface.py:4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m      3\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m iresnet\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OrderedDict\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtermcolor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cprint\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'iresnet' from 'models' (/mnt/c/Dokumenter/Dokumenter/UNI/Master/Thesis/GitHub_Repo/Master_Thesis/notebooks/../models/__init__.py)"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "# from dataloader import dataloader\n",
    "from models import magface\n",
    "from utils import utils\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from termcolor import cprint\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.multiprocessing as mp\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch\n",
    "import argparse\n",
    "import random\n",
    "import warnings\n",
    "import time\n",
    "import pprint\n",
    "import os\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# parse the args\n",
    "cprint('=> parse the args ...', 'green')\n",
    "parser = argparse.ArgumentParser(description='Trainer for Magface')\n",
    "parser.add_argument('--arch', default='resnet100', type=str,\n",
    "                    help='backbone architechture')\n",
    "parser.add_argument('--train_list', default='', type=str,\n",
    "                    help='')\n",
    "\n",
    "parser.add_argument('-j', '--workers', default=4, type=int, metavar='N',\n",
    "                    help='number of data loading workers (default: 4)')\n",
    "parser.add_argument('--epochs', default=90, type=int, metavar='N',\n",
    "                    help='number of total epochs to run')\n",
    "parser.add_argument('--start-epoch', default=0, type=int, metavar='N',\n",
    "                    help='manual epoch number (useful on restarts)')\n",
    "parser.add_argument('-b', '--batch-size', default=512, type=int, metavar='N',\n",
    "                    help='mini-batch size (default: 256), this is the total '\n",
    "                    'batch size of all GPUs on the current node when '\n",
    "                    'using Data Parallel or Distributed Data Parallel')\n",
    "parser.add_argument('--embedding-size', default=512, type=int,\n",
    "                    help='The embedding feature size')\n",
    "parser.add_argument('--last-fc-size', default=1000, type=int,\n",
    "                    help='The num of last fc layers for using softmax')\n",
    "\n",
    "\n",
    "parser.add_argument('--lr', '--learning-rate', default=0.1, type=float,\n",
    "                    metavar='LR', help='initial learning rate', dest='lr')\n",
    "parser.add_argument('--momentum', default=0.9, type=float, metavar='M',\n",
    "                    help='momentum')\n",
    "parser.add_argument('--wd', '--weight-decay', default=1e-4, type=float,\n",
    "                    metavar='W', help='weight decay (default: 1e-4)',\n",
    "                    dest='weight_decay')\n",
    "parser.add_argument('--lr-drop-epoch', default=[30, 60, 90], type=int, nargs='+',\n",
    "                    help='The learning rate drop epoch')\n",
    "parser.add_argument('--lr-drop-ratio', default=0.1, type=float,\n",
    "                    help='The learning rate drop ratio')\n",
    "\n",
    "parser.add_argument('-p', '--print-freq', default=10, type=int,\n",
    "                    metavar='N', help='print frequency (default: 10)')\n",
    "\n",
    "parser.add_argument('--pth-save-fold', default='tmp', type=str,\n",
    "                    help='The folder to save pths')\n",
    "parser.add_argument('--pth-save-epoch', default=1, type=int,\n",
    "                    help='The epoch to save pth')\n",
    "\n",
    "\n",
    "# magface parameters\n",
    "parser.add_argument('--l_a', default=10, type=float,\n",
    "                    help='lower bound of feature norm')\n",
    "parser.add_argument('--u_a', default=110, type=float,\n",
    "                    help='upper bound of feature norm')\n",
    "parser.add_argument('--l_margin', default=0.45,\n",
    "                    type=float, help='low bound of margin')\n",
    "parser.add_argument('--u_margin', default=0.8, type=float,\n",
    "                    help='the margin slop for m')\n",
    "parser.add_argument('--lambda_g', default=20, type=float,\n",
    "                    help='the lambda for function g')\n",
    "parser.add_argument('--arc-scale', default=64, type=int,\n",
    "                    help='scale for arcmargin loss')\n",
    "parser.add_argument('--vis_mag', default=1, type=int,\n",
    "                    help='visualize the magnitude against cos')\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    # check the feasible of the lambda g\n",
    "    s = 64\n",
    "    k = (args.u_margin-args.l_margin)/(args.u_a-args.l_a)\n",
    "    min_lambda = s*k*args.u_a**2*args.l_a**2/(args.u_a**2-args.l_a**2)\n",
    "    color_lambda = 'red' if args.lambda_g < min_lambda else 'green'\n",
    "    cprint('min lambda g is {}, currrent lambda is {}'.format(\n",
    "        min_lambda, args.lambda_g), color_lambda)\n",
    "\n",
    "    cprint('=> torch version : {}'.format(torch.__version__), 'green')\n",
    "    ngpus_per_node = torch.cuda.device_count()\n",
    "    cprint('=> ngpus : {}'.format(ngpus_per_node), 'green')\n",
    "\n",
    "    main_worker(ngpus_per_node, args)\n",
    "\n",
    "\n",
    "def main_worker(ngpus_per_node, args):\n",
    "    global best_acc1\n",
    "\n",
    "    cprint('=> modeling the network ...', 'green')\n",
    "    model = magface.builder(args)\n",
    "    model = torch.nn.DataParallel(model).cuda()\n",
    "    # for name, param in model.named_parameters():\n",
    "    #     cprint(' : layer name and parameter size - {} - {}'.format(name, param.size()), 'green')\n",
    "\n",
    "    cprint('=> building the oprimizer ...', 'green')\n",
    "    optimizer = torch.optim.SGD(\n",
    "        filter(lambda p: p.requires_grad, model.parameters()),\n",
    "        args.lr,\n",
    "        momentum=args.momentum,\n",
    "        weight_decay=args.weight_decay)\n",
    "    pprint.pprint(optimizer)\n",
    "\n",
    "    cprint('=> building the dataloader ...', 'green')\n",
    "    train_loader = dataloader.train_loader(args)\n",
    "\n",
    "    cprint('=> building the criterion ...', 'green')\n",
    "    criterion = magface.MagLoss(\n",
    "        args.l_a, args.u_a, args.l_margin, args.u_margin)\n",
    "\n",
    "    global iters\n",
    "    iters = 0\n",
    "\n",
    "    cprint('=> starting training engine ...', 'green')\n",
    "    for epoch in range(args.start_epoch, args.epochs):\n",
    "\n",
    "        global current_lr\n",
    "        current_lr = utils.adjust_learning_rate(optimizer, epoch, args)\n",
    "\n",
    "        # train for one epoch\n",
    "        do_train(train_loader, model, criterion, optimizer, epoch, args)\n",
    "\n",
    "        # save pth\n",
    "        if epoch % args.pth_save_epoch == 0:\n",
    "            state_dict = model.state_dict()\n",
    "\n",
    "            utils.save_checkpoint({\n",
    "                'epoch': epoch + 1,\n",
    "                'arch': args.arch,\n",
    "                'state_dict': state_dict,\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "            }, False,\n",
    "                filename=os.path.join(\n",
    "                args.pth_save_fold, '{}.pth'.format(\n",
    "                    str(epoch+1).zfill(5))\n",
    "            ))\n",
    "            cprint(' : save pth for epoch {}'.format(epoch + 1))\n",
    "\n",
    "\n",
    "def do_train(train_loader, model, criterion, optimizer, epoch, args):\n",
    "    batch_time = utils.AverageMeter('Time', ':6.3f')\n",
    "    data_time = utils.AverageMeter('Data', ':6.3f')\n",
    "    losses = utils.AverageMeter('Loss', ':.3f')\n",
    "    top1 = utils.AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = utils.AverageMeter('Acc@5', ':6.2f')\n",
    "    learning_rate = utils.AverageMeter('LR', ':.4f')\n",
    "    throughputs = utils.AverageMeter('ThroughPut', ':.2f')\n",
    "\n",
    "    losses_id = utils.AverageMeter('L_ID', ':.3f')\n",
    "    losses_mag = utils.AverageMeter('L_mag', ':.6f')\n",
    "    progress_template = [batch_time, data_time, throughputs, 'images/s',\n",
    "                         losses, losses_id, losses_mag,\n",
    "                         top1, top5, learning_rate]\n",
    "\n",
    "    progress = utils.ProgressMeter(\n",
    "        len(train_loader),\n",
    "        progress_template,\n",
    "        prefix=\"Epoch: [{}]\".format(epoch))\n",
    "    end = time.time()\n",
    "\n",
    "    # update lr\n",
    "    learning_rate.update(current_lr)\n",
    "\n",
    "    for i, (input, target) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        global iters\n",
    "        iters += 1\n",
    "\n",
    "        input = input.cuda(non_blocking=True)\n",
    "        target = target.cuda(non_blocking=True)\n",
    "\n",
    "        # compute output\n",
    "        output, x_norm = model(input, target)\n",
    "\n",
    "        loss_id, loss_g, one_hot = criterion(output, target, x_norm)\n",
    "        loss = loss_id + args.lambda_g * loss_g\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        acc1, acc5 = utils.accuracy(args, output[0], target, topk=(1, 5))\n",
    "\n",
    "        losses.update(loss.item(), input.size(0))\n",
    "        top1.update(acc1[0], input.size(0))\n",
    "        top5.update(acc5[0], input.size(0))\n",
    "\n",
    "        losses_id.update(loss_id.item(), input.size(0))\n",
    "        losses_mag.update(args.lambda_g*loss_g.item(), input.size(0))\n",
    "\n",
    "        # compute gradient and do solver step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        duration = time.time() - end\n",
    "        batch_time.update(duration)\n",
    "        end = time.time()\n",
    "        throughputs.update(args.batch_size / duration)\n",
    "\n",
    "        if i % args.print_freq == 0:\n",
    "            progress.display(i)\n",
    "            debug_info(x_norm, args.l_a, args.u_a,\n",
    "                           args.l_margin, args.u_margin)\n",
    "\n",
    "        if args.vis_mag:\n",
    "            if (i > 10000) and (i % 100 == 0):\n",
    "                x_norm = x_norm.detach().cpu().numpy()\n",
    "                cos_theta = torch.masked_select(\n",
    "                    output[0], one_hot.bool()).detach().cpu().numpy()\n",
    "                logit = torch.masked_select(\n",
    "                    F.softmax(output[0]), one_hot.bool()).detach().cpu().numpy()\n",
    "                np.savez('{}/vis/epoch_{}_iter{}'.format(args.pth_save_fold, epoch, i),\n",
    "                         x_norm, logit, cos_theta)\n",
    "\n",
    "\n",
    "def debug_info(x_norm, l_a, u_a, l_margin, u_margin):\n",
    "    \"\"\"\n",
    "    visualize the magnitudes and magins during training.\n",
    "    Note: modify the function if m(a) is not linear\n",
    "    \"\"\"\n",
    "    mean_ = torch.mean(x_norm).detach().cpu().numpy()\n",
    "    max_ = torch.max(x_norm).detach().cpu().numpy()\n",
    "    min_ = torch.min(x_norm).detach().cpu().numpy()\n",
    "    m_mean_ = (u_margin-l_margin)/(u_a-l_a)*(mean_-l_a) + l_margin\n",
    "    m_max_ = (u_margin-l_margin)/(u_a-l_a)*(max_-l_a) + l_margin\n",
    "    m_min_ = (u_margin-l_margin)/(u_a-l_a)*(min_-l_a) + l_margin\n",
    "    print('  [debug info]: x_norm mean: {:.2f} min: {:.2f} max: {:.2f}'\n",
    "          .format(mean_, min_, max_))\n",
    "    print('  [debug info]: margin mean: {:.2f} min: {:.2f} max: {:.2f}'\n",
    "          .format(m_mean_, m_min_, m_max_))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    pprint.pprint(vars(args))\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "best_master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
