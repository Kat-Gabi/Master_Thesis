{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mated adults \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def list_files_from_subfolders(root_dir):\n",
    "    \"\"\"\n",
    "    List files from subdirectories within the 'adults' root directory which contain more than one subdirectory.\n",
    "\n",
    "    Parameters:\n",
    "        root_dir (str): The root directory containing the 'adults' directory.\n",
    "\n",
    "    Returns:\n",
    "        list of str: Filenames prefixed with their immediate parent directory name from subdirectories that contain more than one subdirectory.\n",
    "    \"\"\"\n",
    "    all_files = []  # List to store filenames\n",
    "    single_files=[]\n",
    "    # Check if the root_dir exists and is a directory\n",
    "    if not os.path.isdir(root_dir):\n",
    "        print(f\"The path {root_dir} is not a valid directory.\")\n",
    "        return all_files\n",
    "\n",
    "    # Iterate over the items in the 'adults' directory\n",
    "    for item in os.listdir(root_dir):\n",
    "        item_path = os.path.join(root_dir, item)\n",
    "        # Proceed only if the item is a directory\n",
    "        if os.path.isdir(item_path):\n",
    "            subdirs = [d for d in os.listdir(item_path) if os.path.isdir(os.path.join(item_path, d))]\n",
    "            # If the current directory contains more than one subdirectory\n",
    "            if len(subdirs) > 1:\n",
    "                # Iterate over each subdirectory\n",
    "                for subdir in subdirs:\n",
    "                    subdir_path = os.path.join(item_path, subdir)\n",
    "                    # Add the file names within this subdirectory to the list\n",
    "                    files = [os.path.join(item, subdir, f) for f in os.listdir(subdir_path) if os.path.isfile(os.path.join(subdir_path, f))]\n",
    "                    all_files.extend(files)\n",
    "            elif len(subdirs)==1:\n",
    "                for subdir in subdirs:\n",
    "                    subdir_path = os.path.join(item_path, subdir)\n",
    "                    # Add the file names within this subdirectory to the list\n",
    "                    files = [os.path.join(item, subdir, f) for f in os.listdir(subdir_path) if os.path.isfile(os.path.join(subdir_path, f))]\n",
    "                    single_files.extend(files)\n",
    "\n",
    "    return all_files, single_files\n",
    "\n",
    "\n",
    "\n",
    "def list_files_from_folders_with_multiple_files_child(root_dir):\n",
    "    \"\"\"\n",
    "    List files from folders within the 'children' root directory that contain more than one file.\n",
    "\n",
    "    Parameters:\n",
    "        root_dir (str): The root directory containing the 'children' directory.\n",
    "\n",
    "    Returns:\n",
    "        list of str: Strings representing each file in the folders that contain more than one file.\n",
    "    \"\"\"\n",
    "    folder_files_list = []  # List to store folder/file strings\n",
    "    single_files_list = []\n",
    "\n",
    "    # Iterate over the items in the 'children' directory\n",
    "    for folder_name in os.listdir(root_dir):\n",
    "        folder_path = os.path.join(root_dir, folder_name)\n",
    "        # Proceed only if the item is a directory\n",
    "        if os.path.isdir(folder_path):\n",
    "            files = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "            # Proceed only if the folder contains more than one file\n",
    "            if len(files) > 1:\n",
    "                # Create a string for each file\n",
    "                for file in files:\n",
    "                    folder_files_list.append(f\"{folder_name}/{file}\")\n",
    "            elif len(files) == 1:\n",
    "                for file in files:\n",
    "                    single_files_list.append(f\"{folder_name}/{file}\")\n",
    "    return folder_files_list,single_files_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_unique_identifiers(file_list):\n",
    "    \"\"\"\n",
    "    Extracts a unique identifier from a list of file paths.\n",
    "\n",
    "    Parameters:\n",
    "        file_list (list): A list of strings containing file paths.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of unique identifiers extracted from the file paths.\n",
    "    \"\"\"\n",
    "    identifiers = []\n",
    "    for file_path in file_list:\n",
    "        # Extract the base filename without extension and path\n",
    "        base_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "        identifiers.append(base_name)\n",
    "\n",
    "    return identifiers\n",
    "\n",
    "\n",
    "def drop_after_zeros(s):\n",
    "    \"\"\"\n",
    "    Drops everything from the input string after the first occurrence of three consecutive zeros\n",
    "    and also drops the last underscore before the zeros.\n",
    "\n",
    "    Parameters:\n",
    "        s (str): The input string.\n",
    "\n",
    "    Returns:\n",
    "        str: The string up to, but not including, the last underscore before the three consecutive zeros.\n",
    "    \"\"\"\n",
    "    # Find the index of the first occurrence of three consecutive zeros\n",
    "    zero_index = s.find('000')\n",
    "\n",
    "    # If three consecutive zeros are found\n",
    "    if zero_index != -1:\n",
    "        # Find the last underscore before the '000'\n",
    "        underscore_index = s.rfind('_', 0, zero_index)\n",
    "        # If an underscore is found, return the substring up to that point\n",
    "        if underscore_index != -1:\n",
    "            return s[:underscore_index]\n",
    "        else:\n",
    "            return s[:zero_index]\n",
    "    else:\n",
    "        return s  # If no '000' sequence is found, return the original string\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "def load_data(path):\n",
    "    f = open(path)\n",
    "    data = json.load(f)\n",
    "    df = pd.DataFrame.from_dict(data, orient='index', columns=['Age'])\n",
    "    f.close()\n",
    "\n",
    "    # removing nans\n",
    "    nans = df['Age'].isna().sum()\n",
    "    df = df.dropna()\n",
    "\n",
    "    describe = df.describe()\n",
    "    value_counts = df.value_counts()\n",
    "\n",
    "    # make new column for the identity based on the index\n",
    "    df['Identity'] = df.index\n",
    "    df['Identity'] = df.index.str.rsplit('_', 1).str[0]\n",
    "\n",
    "    df = df.sort_values(by='Age')\n",
    "\n",
    "    return df, nans, describe, value_counts\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def drop_number_after_last_underscore(df, column_name):\n",
    "    \"\"\"\n",
    "    Drops the number after the last underscore from the string in the specified column of a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The DataFrame containing the column to process.\n",
    "        column_name (str): The name of the column to process.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with the modified column.\n",
    "    \"\"\"\n",
    "    # Check if the column exists in the DataFrame\n",
    "    if column_name in df.columns:\n",
    "        # Split the string by underscore and drop the last part\n",
    "        df[column_name] = df[column_name].apply(lambda x: '_'.join(x.split('_')[:-1]))\n",
    "    else:\n",
    "        raise ValueError(f\"The column {column_name} does not exist in the DataFrame.\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_YLFW = load_data('/mnt/c/Dokumenter/Dokumenter/UNI/Master/Thesis/GitHub_Repo/Master_Thesis/data/age_estimations/YLFW_output_data_precroped_all_age.json')[0]\n",
    "df_RFW_african = load_data('/mnt/c/Dokumenter/Dokumenter/UNI/Master/Thesis/GitHub_Repo/Master_Thesis/data/age_estimations/data sendt fra Gabi senest/output_african.json')[0]\n",
    "df_RFW_asian = load_data('/mnt/c/Dokumenter/Dokumenter/UNI/Master/Thesis/GitHub_Repo/Master_Thesis/data/age_estimations/data sendt fra Gabi senest/output_asian.json')[0]\n",
    "df_RFW_caucasian = load_data('/mnt/c/Dokumenter/Dokumenter/UNI/Master/Thesis/GitHub_Repo/Master_Thesis/data/age_estimations/data sendt fra Gabi senest/output_caucasian.json')[0]\n",
    "df_RFW_indian = load_data('/mnt/c/Dokumenter/Dokumenter/UNI/Master/Thesis/GitHub_Repo/Master_Thesis/data/age_estimations/data sendt fra Gabi senest/output_indian.json')[0]\n",
    "df_RFW = pd.concat([df_RFW_african, df_RFW_asian, df_RFW_caucasian, df_RFW_indian])\n",
    "df_RFW.Age = df_RFW.Age.astype(int)\n",
    "df_RFW = df_RFW.sort_values(by='Age', ascending=True)\n",
    "\n",
    "age_df = pd.concat([df_YLFW,df_RFW])\n",
    "age_df['image_name'] = age_df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mated adults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "adults_dir = '/mnt/c/Dokumenter/Dokumenter/UNI/Master/Thesis/GitHub_Repo/Master_Thesis/data/raw_full/adults/'\n",
    "files_list = list_files_from_subfolders(adults_dir)[0]\n",
    "image_names = extract_unique_identifiers(files_list)\n",
    "\n",
    "identity_names = []\n",
    "for i in image_names:\n",
    "    identity_name = drop_after_zeros(i)\n",
    "\n",
    "    identity_names.append(identity_name)\n",
    "\n",
    "DF = pd.DataFrame(\n",
    "    {'files_list': files_list,\n",
    "     'image_name': image_names,\n",
    "     'identity_name': identity_names,\n",
    "     'enrolled' : 'enrolled'})\n",
    "DF['ethnicity'] = DF['files_list'].apply(lambda x: x.split('_')[0] if isinstance(x, str) and x.split() else None)\n",
    "OFIQ_a = pd.read_csv('/mnt/c/Dokumenter/Dokumenter/UNI/Master/Thesis/GitHub_Repo/Master_Thesis/data/OFIQ_results/adults_all_final.csv', sep=';')\n",
    "OFIQ_c = pd.read_csv('/mnt/c/Dokumenter/Dokumenter/UNI/Master/Thesis/GitHub_Repo/Master_Thesis/data/OFIQ_results/children_all_final.csv', sep=';')\n",
    "OFIQ_c['image_name']= OFIQ_c['Filename'].apply(lambda x: x.split('/')[-1])\n",
    "OFIQ_c['image_name']= OFIQ_c['image_name'].apply(lambda x: x.split('.')[0])\n",
    "OFIQ_a['image_name']=OFIQ_a['Filename'].apply(lambda x: x.split('/')[-1])\n",
    "OFIQ_a['image_name']=OFIQ_a['image_name'].apply(lambda x: x.split('.jpg')[0])\n",
    "OFIQ = pd.concat([OFIQ_a,OFIQ_c])\n",
    "\n",
    "final_adult = pd.merge(DF, age_df, on='image_name', how='left')\n",
    "final_adult = final_adult.merge(OFIQ[['image_name', 'UnifiedQualityScore.scalar']],\n",
    "                                on='image_name',\n",
    "                                how='left')\n",
    "final_adult.to_csv('mated_adults_image_info.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>files_list</th>\n",
       "      <th>image_name</th>\n",
       "      <th>identity_name</th>\n",
       "      <th>enrolled</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>Age</th>\n",
       "      <th>Identity</th>\n",
       "      <th>UnifiedQualityScore.scalar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>African_m.012mh_/m.012mh__0001.jpg/m.012mh__00...</td>\n",
       "      <td>m.012mh__0001</td>\n",
       "      <td>m.012mh_</td>\n",
       "      <td>enrolled</td>\n",
       "      <td>African</td>\n",
       "      <td>24</td>\n",
       "      <td>m.012mh_</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>African_m.012mh_/m.012mh__0005.jpg/m.012mh__00...</td>\n",
       "      <td>m.012mh__0005</td>\n",
       "      <td>m.012mh_</td>\n",
       "      <td>enrolled</td>\n",
       "      <td>African</td>\n",
       "      <td>24</td>\n",
       "      <td>m.012mh_</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>African_m.01c_3f/m.01c_3f_0002.jpg/m.01c_3f_00...</td>\n",
       "      <td>m.01c_3f_0002</td>\n",
       "      <td>m.01c_3f</td>\n",
       "      <td>enrolled</td>\n",
       "      <td>African</td>\n",
       "      <td>43</td>\n",
       "      <td>m.01c_3f</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>African_m.01c_3f/m.01c_3f_0003.jpg/m.01c_3f_00...</td>\n",
       "      <td>m.01c_3f_0003</td>\n",
       "      <td>m.01c_3f</td>\n",
       "      <td>enrolled</td>\n",
       "      <td>African</td>\n",
       "      <td>33</td>\n",
       "      <td>m.01c_3f</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>African_m.01jq08_/m.01jq08__0001.jpg/m.01jq08_...</td>\n",
       "      <td>m.01jq08__0001</td>\n",
       "      <td>m.01jq08_</td>\n",
       "      <td>enrolled</td>\n",
       "      <td>African</td>\n",
       "      <td>41</td>\n",
       "      <td>m.01jq08_</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>Indian_m.0nhj8xl/m.0nhj8xl_0004.jpg/m.0nhj8xl_...</td>\n",
       "      <td>m.0nhj8xl_0004</td>\n",
       "      <td>m.0nhj8xl</td>\n",
       "      <td>enrolled</td>\n",
       "      <td>Indian</td>\n",
       "      <td>25</td>\n",
       "      <td>m.0nhj8xl</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>Indian_m.0q2y9_v/m.0q2y9_v_0002.jpg/m.0q2y9_v_...</td>\n",
       "      <td>m.0q2y9_v_0002</td>\n",
       "      <td>m.0q2y9_v</td>\n",
       "      <td>enrolled</td>\n",
       "      <td>Indian</td>\n",
       "      <td>25</td>\n",
       "      <td>m.0q2y9_v</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>Indian_m.0q2y9_v/m.0q2y9_v_0003.jpg/m.0q2y9_v_...</td>\n",
       "      <td>m.0q2y9_v_0003</td>\n",
       "      <td>m.0q2y9_v</td>\n",
       "      <td>enrolled</td>\n",
       "      <td>Indian</td>\n",
       "      <td>30</td>\n",
       "      <td>m.0q2y9_v</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>Indian_m.0tj9/m.0tj9_0002.jpg/m.0tj9_0002.jpg</td>\n",
       "      <td>m.0tj9_0002</td>\n",
       "      <td>m.0tj9</td>\n",
       "      <td>enrolled</td>\n",
       "      <td>Indian</td>\n",
       "      <td>38</td>\n",
       "      <td>m.0tj9</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>Indian_m.0tj9/m.0tj9_0005.jpg/m.0tj9_0005.jpg</td>\n",
       "      <td>m.0tj9_0005</td>\n",
       "      <td>m.0tj9</td>\n",
       "      <td>enrolled</td>\n",
       "      <td>Indian</td>\n",
       "      <td>48</td>\n",
       "      <td>m.0tj9</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>773 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            files_list      image_name  \\\n",
       "0    African_m.012mh_/m.012mh__0001.jpg/m.012mh__00...   m.012mh__0001   \n",
       "1    African_m.012mh_/m.012mh__0005.jpg/m.012mh__00...   m.012mh__0005   \n",
       "2    African_m.01c_3f/m.01c_3f_0002.jpg/m.01c_3f_00...   m.01c_3f_0002   \n",
       "3    African_m.01c_3f/m.01c_3f_0003.jpg/m.01c_3f_00...   m.01c_3f_0003   \n",
       "4    African_m.01jq08_/m.01jq08__0001.jpg/m.01jq08_...  m.01jq08__0001   \n",
       "..                                                 ...             ...   \n",
       "768  Indian_m.0nhj8xl/m.0nhj8xl_0004.jpg/m.0nhj8xl_...  m.0nhj8xl_0004   \n",
       "769  Indian_m.0q2y9_v/m.0q2y9_v_0002.jpg/m.0q2y9_v_...  m.0q2y9_v_0002   \n",
       "770  Indian_m.0q2y9_v/m.0q2y9_v_0003.jpg/m.0q2y9_v_...  m.0q2y9_v_0003   \n",
       "771      Indian_m.0tj9/m.0tj9_0002.jpg/m.0tj9_0002.jpg     m.0tj9_0002   \n",
       "772      Indian_m.0tj9/m.0tj9_0005.jpg/m.0tj9_0005.jpg     m.0tj9_0005   \n",
       "\n",
       "    identity_name  enrolled ethnicity Age   Identity  \\\n",
       "0        m.012mh_  enrolled   African  24   m.012mh_   \n",
       "1        m.012mh_  enrolled   African  24   m.012mh_   \n",
       "2        m.01c_3f  enrolled   African  43   m.01c_3f   \n",
       "3        m.01c_3f  enrolled   African  33   m.01c_3f   \n",
       "4       m.01jq08_  enrolled   African  41  m.01jq08_   \n",
       "..            ...       ...       ...  ..        ...   \n",
       "768     m.0nhj8xl  enrolled    Indian  25  m.0nhj8xl   \n",
       "769     m.0q2y9_v  enrolled    Indian  25  m.0q2y9_v   \n",
       "770     m.0q2y9_v  enrolled    Indian  30  m.0q2y9_v   \n",
       "771        m.0tj9  enrolled    Indian  38     m.0tj9   \n",
       "772        m.0tj9  enrolled    Indian  48     m.0tj9   \n",
       "\n",
       "     UnifiedQualityScore.scalar  \n",
       "0                          59.0  \n",
       "1                          46.0  \n",
       "2                          19.0  \n",
       "3                          49.0  \n",
       "4                          23.0  \n",
       "..                          ...  \n",
       "768                        17.0  \n",
       "769                        44.0  \n",
       "770                         4.0  \n",
       "771                        24.0  \n",
       "772                        71.0  \n",
       "\n",
       "[773 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_adult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nonmated adults\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "adults_dir = '/mnt/c/Dokumenter/Dokumenter/UNI/Master/Thesis/GitHub_Repo/Master_Thesis/data/raw_full/adults/'\n",
    "files_list = list_files_from_subfolders(adults_dir)[1]\n",
    "image_names = extract_unique_identifiers(files_list)\n",
    "\n",
    "identity_names = []\n",
    "for i in image_names:\n",
    "    identity_name = drop_after_zeros(i)\n",
    "\n",
    "    identity_names.append(identity_name)\n",
    "\n",
    "DF = pd.DataFrame(\n",
    "    {'files_list': files_list,\n",
    "     'image_name': image_names,\n",
    "     'identity_name': identity_names,\n",
    "     'enrolled' : 'non_enrolled'})\n",
    "DF['ethnicity'] = DF['files_list'].apply(lambda x: x.split('_')[0] if isinstance(x, str) and x.split() else None)\n",
    "OFIQ_a = pd.read_csv('/mnt/c/Dokumenter/Dokumenter/UNI/Master/Thesis/GitHub_Repo/Master_Thesis/data/OFIQ_results/adults_all_final.csv', sep=';')\n",
    "OFIQ_c = pd.read_csv('/mnt/c/Dokumenter/Dokumenter/UNI/Master/Thesis/GitHub_Repo/Master_Thesis/data/OFIQ_results/children_all_final.csv', sep=';')\n",
    "OFIQ_c['image_name']= OFIQ_c['Filename'].apply(lambda x: x.split('/')[-1])\n",
    "OFIQ_c['image_name']= OFIQ_c['image_name'].apply(lambda x: x.split('.')[0])\n",
    "OFIQ_a['image_name']=OFIQ_a['Filename'].apply(lambda x: x.split('/')[-1])\n",
    "OFIQ_a['image_name']=OFIQ_a['image_name'].apply(lambda x: x.split('.jpg')[0])\n",
    "OFIQ = pd.concat([OFIQ_a,OFIQ_c])\n",
    "\n",
    "final_adult = pd.merge(DF, age_df, on='image_name', how='left')\n",
    "final_adult_non = final_adult.merge(OFIQ[['image_name', 'UnifiedQualityScore.scalar']],\n",
    "                                on='image_name',\n",
    "                                how='left')\n",
    "final_adult_non.to_csv('nonmated_adults_image_info.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>files_list</th>\n",
       "      <th>image_name</th>\n",
       "      <th>identity_name</th>\n",
       "      <th>enrolled</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>Age</th>\n",
       "      <th>Identity</th>\n",
       "      <th>UnifiedQualityScore.scalar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>African_m.015pz3/m.015pz3_0003.jpg/m.015pz3_00...</td>\n",
       "      <td>m.015pz3_0003</td>\n",
       "      <td>m.015pz3</td>\n",
       "      <td>non_enrolled</td>\n",
       "      <td>African</td>\n",
       "      <td>56</td>\n",
       "      <td>m.015pz3</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>African_m.015q3m/m.015q3m_0004.jpg/m.015q3m_00...</td>\n",
       "      <td>m.015q3m_0004</td>\n",
       "      <td>m.015q3m</td>\n",
       "      <td>non_enrolled</td>\n",
       "      <td>African</td>\n",
       "      <td>35</td>\n",
       "      <td>m.015q3m</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>African_m.0183qt/m.0183qt_0006.jpg/m.0183qt_00...</td>\n",
       "      <td>m.0183qt_0006</td>\n",
       "      <td>m.0183qt</td>\n",
       "      <td>non_enrolled</td>\n",
       "      <td>African</td>\n",
       "      <td>39</td>\n",
       "      <td>m.0183qt</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>African_m.01f97r/m.01f97r_0003.jpg/m.01f97r_00...</td>\n",
       "      <td>m.01f97r_0003</td>\n",
       "      <td>m.01f97r</td>\n",
       "      <td>non_enrolled</td>\n",
       "      <td>African</td>\n",
       "      <td>57</td>\n",
       "      <td>m.01f97r</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>African_m.01flf5/m.01flf5_0003.jpg/m.01flf5_00...</td>\n",
       "      <td>m.01flf5_0003</td>\n",
       "      <td>m.01flf5</td>\n",
       "      <td>non_enrolled</td>\n",
       "      <td>African</td>\n",
       "      <td>33</td>\n",
       "      <td>m.01flf5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2724</th>\n",
       "      <td>Indian_m.0qfr7xm/m.0qfr7xm_0002.jpg/m.0qfr7xm_...</td>\n",
       "      <td>m.0qfr7xm_0002</td>\n",
       "      <td>m.0qfr7xm</td>\n",
       "      <td>non_enrolled</td>\n",
       "      <td>Indian</td>\n",
       "      <td>23</td>\n",
       "      <td>m.0qfr7xm</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2725</th>\n",
       "      <td>Indian_m.0r8l061/m.0r8l061_0002.jpg/m.0r8l061_...</td>\n",
       "      <td>m.0r8l061_0002</td>\n",
       "      <td>m.0r8l061</td>\n",
       "      <td>non_enrolled</td>\n",
       "      <td>Indian</td>\n",
       "      <td>21</td>\n",
       "      <td>m.0r8l061</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2726</th>\n",
       "      <td>Indian_m.0r8ntwm/m.0r8ntwm_0001.jpg/m.0r8ntwm_...</td>\n",
       "      <td>m.0r8ntwm_0001</td>\n",
       "      <td>m.0r8ntwm</td>\n",
       "      <td>non_enrolled</td>\n",
       "      <td>Indian</td>\n",
       "      <td>23</td>\n",
       "      <td>m.0r8ntwm</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2727</th>\n",
       "      <td>Indian_m.0rpj1kv/m.0rpj1kv_0003.jpg/m.0rpj1kv_...</td>\n",
       "      <td>m.0rpj1kv_0003</td>\n",
       "      <td>m.0rpj1kv</td>\n",
       "      <td>non_enrolled</td>\n",
       "      <td>Indian</td>\n",
       "      <td>38</td>\n",
       "      <td>m.0rpj1kv</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2728</th>\n",
       "      <td>Indian_m.0_4pw/m.0_4pw_0001.jpg/m.0_4pw_0001.jpg</td>\n",
       "      <td>m.0_4pw_0001</td>\n",
       "      <td>m.0_4pw</td>\n",
       "      <td>non_enrolled</td>\n",
       "      <td>Indian</td>\n",
       "      <td>38</td>\n",
       "      <td>m.0_4pw</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2729 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             files_list      image_name  \\\n",
       "0     African_m.015pz3/m.015pz3_0003.jpg/m.015pz3_00...   m.015pz3_0003   \n",
       "1     African_m.015q3m/m.015q3m_0004.jpg/m.015q3m_00...   m.015q3m_0004   \n",
       "2     African_m.0183qt/m.0183qt_0006.jpg/m.0183qt_00...   m.0183qt_0006   \n",
       "3     African_m.01f97r/m.01f97r_0003.jpg/m.01f97r_00...   m.01f97r_0003   \n",
       "4     African_m.01flf5/m.01flf5_0003.jpg/m.01flf5_00...   m.01flf5_0003   \n",
       "...                                                 ...             ...   \n",
       "2724  Indian_m.0qfr7xm/m.0qfr7xm_0002.jpg/m.0qfr7xm_...  m.0qfr7xm_0002   \n",
       "2725  Indian_m.0r8l061/m.0r8l061_0002.jpg/m.0r8l061_...  m.0r8l061_0002   \n",
       "2726  Indian_m.0r8ntwm/m.0r8ntwm_0001.jpg/m.0r8ntwm_...  m.0r8ntwm_0001   \n",
       "2727  Indian_m.0rpj1kv/m.0rpj1kv_0003.jpg/m.0rpj1kv_...  m.0rpj1kv_0003   \n",
       "2728   Indian_m.0_4pw/m.0_4pw_0001.jpg/m.0_4pw_0001.jpg    m.0_4pw_0001   \n",
       "\n",
       "     identity_name      enrolled ethnicity Age   Identity  \\\n",
       "0         m.015pz3  non_enrolled   African  56   m.015pz3   \n",
       "1         m.015q3m  non_enrolled   African  35   m.015q3m   \n",
       "2         m.0183qt  non_enrolled   African  39   m.0183qt   \n",
       "3         m.01f97r  non_enrolled   African  57   m.01f97r   \n",
       "4         m.01flf5  non_enrolled   African  33   m.01flf5   \n",
       "...            ...           ...       ...  ..        ...   \n",
       "2724     m.0qfr7xm  non_enrolled    Indian  23  m.0qfr7xm   \n",
       "2725     m.0r8l061  non_enrolled    Indian  21  m.0r8l061   \n",
       "2726     m.0r8ntwm  non_enrolled    Indian  23  m.0r8ntwm   \n",
       "2727     m.0rpj1kv  non_enrolled    Indian  38  m.0rpj1kv   \n",
       "2728       m.0_4pw  non_enrolled    Indian  38    m.0_4pw   \n",
       "\n",
       "      UnifiedQualityScore.scalar  \n",
       "0                           51.0  \n",
       "1                           17.0  \n",
       "2                           32.0  \n",
       "3                           53.0  \n",
       "4                            1.0  \n",
       "...                          ...  \n",
       "2724                         8.0  \n",
       "2725                         8.0  \n",
       "2726                        10.0  \n",
       "2727                        73.0  \n",
       "2728                        28.0  \n",
       "\n",
       "[2729 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_adult_non"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mated children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "child_dir = '/mnt/c/Dokumenter/Dokumenter/UNI/Master/Thesis/GitHub_Repo/Master_Thesis/data/raw_full/children/'\n",
    "# files_list = list_files_from_subfolders(child_dir)\n",
    "files_list_child = list_files_from_folders_with_multiple_files_child(child_dir)[0]\n",
    "\n",
    "image_names = extract_unique_identifiers(files_list_child)\n",
    "\n",
    "identity_names = []\n",
    "for i in image_names:\n",
    "    identity_names.append(drop_after_zeros(i))\n",
    "DF_child = pd.DataFrame(\n",
    "    {'files_list': files_list_child,\n",
    "     'image_name': image_names,\n",
    "     'enrolled' : 'enrolled'})\n",
    "\n",
    "DF_child['identity_name'] = DF_child['image_name'].apply(lambda x: '_'.join(x.split('_')[:-1]) if isinstance(x, str) and x.split() else None)\n",
    "DF_child['ethnicity'] = DF_child['files_list'].apply(lambda x: x.split('_')[0] if isinstance(x, str) and x.split() else None)\n",
    "final_child = pd.merge(DF_child, age_df, on='image_name', how='left')\n",
    "final_child_mated = final_child.merge(OFIQ[['image_name', 'UnifiedQualityScore.scalar']],\n",
    "                                on='image_name',\n",
    "                                how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_child_mated.to_csv('mated_children_image_info.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non mated children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "child_dir = '/mnt/c/Dokumenter/Dokumenter/UNI/Master/Thesis/GitHub_Repo/Master_Thesis/data/raw_full/children/'\n",
    "files_list_child = list_files_from_folders_with_multiple_files_child(child_dir)[1]\n",
    "\n",
    "image_names = extract_unique_identifiers(files_list_child)\n",
    "\n",
    "identity_names = []\n",
    "for i in image_names:\n",
    "    identity_names.append(drop_after_zeros(i))\n",
    "DF_child = pd.DataFrame(\n",
    "    {'files_list': files_list_child,\n",
    "     'image_name': image_names,\n",
    "     'enrolled' : 'non_enrolled'})\n",
    "\n",
    "DF_child['identity_name'] = DF_child['image_name'].apply(lambda x: '_'.join(x.split('_')[:-1]) if isinstance(x, str) and x.split() else None)\n",
    "DF_child['ethnicity'] = DF_child['files_list'].apply(lambda x: x.split('_')[0] if isinstance(x, str) and x.split() else None)\n",
    "final_child = pd.merge(DF_child, age_df, on='image_name', how='left')\n",
    "final_child_non = final_child.merge(OFIQ[['image_name', 'UnifiedQualityScore.scalar']],\n",
    "                                on='image_name',\n",
    "                                how='left')\n",
    "final_child_non.to_csv('nonmated_children_image_info.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>files_list</th>\n",
       "      <th>image_name</th>\n",
       "      <th>enrolled</th>\n",
       "      <th>identity_name</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>Age</th>\n",
       "      <th>Identity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>African_0/African_0_1.png</td>\n",
       "      <td>African_0_1</td>\n",
       "      <td>non_enrolled</td>\n",
       "      <td>African_0</td>\n",
       "      <td>African</td>\n",
       "      <td>18</td>\n",
       "      <td>African_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>African_1/African_1_11.png</td>\n",
       "      <td>African_1_11</td>\n",
       "      <td>non_enrolled</td>\n",
       "      <td>African_1</td>\n",
       "      <td>African</td>\n",
       "      <td>5</td>\n",
       "      <td>African_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>African_108/African_108_9.png</td>\n",
       "      <td>African_108_9</td>\n",
       "      <td>non_enrolled</td>\n",
       "      <td>African_108</td>\n",
       "      <td>African</td>\n",
       "      <td>0</td>\n",
       "      <td>African_108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>African_110/African_110_0.png</td>\n",
       "      <td>African_110_0</td>\n",
       "      <td>non_enrolled</td>\n",
       "      <td>African_110</td>\n",
       "      <td>African</td>\n",
       "      <td>14</td>\n",
       "      <td>African_110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>African_116/African_116_3.png</td>\n",
       "      <td>African_116_3</td>\n",
       "      <td>non_enrolled</td>\n",
       "      <td>African_116</td>\n",
       "      <td>African</td>\n",
       "      <td>3</td>\n",
       "      <td>African_116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>Indian_m.0hnbj9t/m.0hnbj9t_0001.jpg</td>\n",
       "      <td>m.0hnbj9t_0001</td>\n",
       "      <td>non_enrolled</td>\n",
       "      <td>m.0hnbj9t</td>\n",
       "      <td>Indian</td>\n",
       "      <td>18</td>\n",
       "      <td>m.0hnbj9t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>Indian_m.0hncksb/m.0hncksb_0001.jpg</td>\n",
       "      <td>m.0hncksb_0001</td>\n",
       "      <td>non_enrolled</td>\n",
       "      <td>m.0hncksb</td>\n",
       "      <td>Indian</td>\n",
       "      <td>18</td>\n",
       "      <td>m.0hncksb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>Indian_m.0j4c85h/m.0j4c85h_0006.jpg</td>\n",
       "      <td>m.0j4c85h_0006</td>\n",
       "      <td>non_enrolled</td>\n",
       "      <td>m.0j4c85h</td>\n",
       "      <td>Indian</td>\n",
       "      <td>17</td>\n",
       "      <td>m.0j4c85h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>Indian_m.0k3208/m.0k3208_0001.jpg</td>\n",
       "      <td>m.0k3208_0001</td>\n",
       "      <td>non_enrolled</td>\n",
       "      <td>m.0k3208</td>\n",
       "      <td>Indian</td>\n",
       "      <td>18</td>\n",
       "      <td>m.0k3208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1217</th>\n",
       "      <td>Indian_m.0r8ntwm/m.0r8ntwm_0003.jpg</td>\n",
       "      <td>m.0r8ntwm_0003</td>\n",
       "      <td>non_enrolled</td>\n",
       "      <td>m.0r8ntwm</td>\n",
       "      <td>Indian</td>\n",
       "      <td>18</td>\n",
       "      <td>m.0r8ntwm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1218 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               files_list      image_name      enrolled  \\\n",
       "0               African_0/African_0_1.png     African_0_1  non_enrolled   \n",
       "1              African_1/African_1_11.png    African_1_11  non_enrolled   \n",
       "2           African_108/African_108_9.png   African_108_9  non_enrolled   \n",
       "3           African_110/African_110_0.png   African_110_0  non_enrolled   \n",
       "4           African_116/African_116_3.png   African_116_3  non_enrolled   \n",
       "...                                   ...             ...           ...   \n",
       "1213  Indian_m.0hnbj9t/m.0hnbj9t_0001.jpg  m.0hnbj9t_0001  non_enrolled   \n",
       "1214  Indian_m.0hncksb/m.0hncksb_0001.jpg  m.0hncksb_0001  non_enrolled   \n",
       "1215  Indian_m.0j4c85h/m.0j4c85h_0006.jpg  m.0j4c85h_0006  non_enrolled   \n",
       "1216    Indian_m.0k3208/m.0k3208_0001.jpg   m.0k3208_0001  non_enrolled   \n",
       "1217  Indian_m.0r8ntwm/m.0r8ntwm_0003.jpg  m.0r8ntwm_0003  non_enrolled   \n",
       "\n",
       "     identity_name ethnicity  Age     Identity  \n",
       "0        African_0   African   18    African_0  \n",
       "1        African_1   African    5    African_1  \n",
       "2      African_108   African    0  African_108  \n",
       "3      African_110   African   14  African_110  \n",
       "4      African_116   African    3  African_116  \n",
       "...            ...       ...  ...          ...  \n",
       "1213     m.0hnbj9t    Indian   18    m.0hnbj9t  \n",
       "1214     m.0hncksb    Indian   18    m.0hncksb  \n",
       "1215     m.0j4c85h    Indian   17    m.0j4c85h  \n",
       "1216      m.0k3208    Indian   18     m.0k3208  \n",
       "1217     m.0r8ntwm    Indian   18    m.0r8ntwm  \n",
       "\n",
       "[1218 rows x 7 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Katrine_MLOps_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
