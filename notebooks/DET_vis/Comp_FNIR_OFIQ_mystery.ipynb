{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load libraries\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import normalize\n",
    "import sys\n",
    "sns.set(style=\"white\")\n",
    "%matplotlib inline\n",
    "sys.path.append('../../utils')\n",
    "from Model_utils.Model_funcs import *\n",
    "from Data_proc_utils.Data_proc_funcs import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all features from feature lists from magface model\n",
    "\n",
    "feature_list_children = '../../data/data_full/feature_vectors/magface_feature_vectors/feat_img_children_full.list'\n",
    "feature_list_adults = '../../data/data_full/feature_vectors/magface_feature_vectors/feat_img_adults_full.list'\n",
    "\n",
    "image_names_c, ids_c, num_ids_c, norm_feats_c = load_magface_vectors(feature_list_children)\n",
    "image_names_a, ids_a, num_ids_a, norm_feats_a = load_magface_vectors(feature_list_adults)\n",
    "\n",
    "# Similarity matrices from magface - all\n",
    "sim_mat_c = np.dot(norm_feats_c, norm_feats_c.T)\n",
    "sim_mat_a = np.dot(norm_feats_a, norm_feats_a.T)\n",
    "\n",
    "# Dataframes with info, removes names not in magface results\n",
    "children_all = pd.read_csv('../../data/image_info_csvs/final_filtered_children_df_BIBEL.csv') #erstat med den opdaterede\n",
    "children_all = children_all[children_all.image_name.isin(image_names_c)]\n",
    "adults_all = pd.read_csv('../../data/image_info_csvs/final_filtered_adults_df_BIBEL.csv') #erstat med den opdaterede\n",
    "adults_all = adults_all[adults_all.image_name.isin(image_names_a)] # OBS, this operation because some magface images has not been through all adults images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for calculating FNIR\n",
    "## Function for calculating FNIR\n",
    "def GET_SIM_MATRIX_HIGH_TH(enrolled_sim_mat, sim_mat, enrolled_ids, enrolled_num_id, ids, thold=0.5):\n",
    "    \"\"\"\n",
    "    FNIR formula from ISO standard ISO/IEC 19795-1:2021\n",
    "    ids: unique ids for all images in results\n",
    "    enrolled_ids: ids for the enrolled images\n",
    "    enrolled_sim_mat: enrolled similarity matrix\n",
    "    sim_mat: all similarity scores\n",
    "    \"\"\"\n",
    "    # M_D: set of mated identification transactions with reference database. - i.e. there can be multiple ids?\n",
    "    M_d_set = set(enrolled_ids)\n",
    "    M_d_set_len = len(enrolled_sim_mat)\n",
    "    neg_ref = 0\n",
    "\n",
    "    # For each id corresponding to the id in the set, check if one of it's corresponding ids are above threshold\n",
    "\n",
    "    # Get enrolled similarity scores\n",
    "    enrolled_sim_scores = []\n",
    "    high_threhols_liste = []\n",
    "\n",
    "    ## Iterate over each enrolled reference for transaction i\n",
    "    for m_i, id_now in enumerate(ids):\n",
    "        # Check if the identity is enrolled\n",
    "        if id_now in M_d_set:\n",
    "            mated_ids_exact = [id == id_now for id in ids] # Array of true and falses\n",
    "            mated_sim_scores_slice = sim_mat[m_i] # Row corresponding to the enrolled probe id\n",
    "            mated_sim_scores_slice_slice = [value for value, keep in zip(mated_sim_scores_slice, mated_ids_exact) if keep] #Only enrolled similarity scores for the same ids corresponding to the probe id\n",
    "            # sort long list (mated_sim_scores_slice_slice) to top 3 for this probe (navn mangler)\n",
    "            # vi vil gerne extend til liste med probe, ref navn\n",
    "\n",
    "\n",
    "\n",
    "            enrolled_sim_scores.extend(mated_sim_scores_slice_slice)\n",
    "\n",
    "\n",
    "    # Iterate over each enrolled reference for transaction i\n",
    "    for i in range(M_d_set_len):\n",
    "        probe = enrolled_num_id[i] # numerical id by magface, e.g. str value \"African_244\" becomes num. value 35.\n",
    "\n",
    "        # Check if the reference probe id is in negative list/below threshold\n",
    "        classified_negative_list = enrolled_sim_mat[i] <= thold\n",
    "        classified_negative_idx = list(np.where(classified_negative_list)[0])  # Get indexes where the score is below threshold\n",
    "        face_idx_neg_class = enrolled_num_id[classified_negative_idx]  # Get numerical ids in the negative class\n",
    "        # If numerical id in negative list is equal to the probe id, count 1\n",
    "        if probe in face_idx_neg_class:\n",
    "            neg_ref += 1\n",
    "\n",
    "    # Calculate FNIR\n",
    "    fnir = neg_ref / M_d_set_len\n",
    "\n",
    "    enrolled_sim_scores_final = np.array(enrolled_sim_scores)\n",
    "    enrolled_sim_scores_final = enrolled_sim_scores_final[enrolled_sim_scores_final<0.999]\n",
    "\n",
    "    i = 0\n",
    "    while len(enrolled_sim_scores_final) > (len(enrolled_sim_scores)-len(enrolled_ids)):\n",
    "        i += 0.001\n",
    "        print(\"NOT SAME LENGTH\", len(enrolled_sim_scores_final), len(enrolled_sim_scores)-len(enrolled_ids))\n",
    "        enrolled_sim_scores_final = enrolled_sim_scores_final[enrolled_sim_scores_final<0.999+i]\n",
    "\n",
    "    return fnir, enrolled_sim_scores_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_states = [3]#[1,2,3,4,5,6,7,8,9,10]\n",
    "sim_mat_dict_all_magface_ex1_1 = {}\n",
    "FNIR_c_list=[]\n",
    "FNIR_a_list=[]\n",
    "FPIR_c_list=[]\n",
    "FPIR_a_list=[]\n",
    "FPD_list=[]\n",
    "FND_list=[]\n",
    "GARBE_list=[]\n",
    "\n",
    "for random_state_i in random_states:\n",
    "\n",
    "    ### Load children and adults balanced data ###\n",
    "    children_balanced_df_i = balance_child_data(children_all, print_stats=False, random_state=random_state_i)\n",
    "    adults_balanced_df_i = balance_adults_data_enrolled(children_balanced_df_i, adults_all, print_stats=False, random_state=random_state_i)\n",
    "\n",
    "\n",
    "    ### All reference image names, enrolled and non-enrolled image names - children ###\n",
    "    c_mates = children_balanced_df_i.groupby(\"identity_name\").agg({'identity_name': ['count']})\n",
    "    enrolled_identity_names_c = c_mates[c_mates[('identity_name', 'count')] > 1].index\n",
    "    enrolled_image_names_c = list(children_balanced_df_i[children_balanced_df_i[\"identity_name\"].isin(enrolled_identity_names_c)].image_name)\n",
    "    non_enrolled_identity_names_c = c_mates[c_mates[('identity_name', 'count')] == 1].index\n",
    "    non_enrolled_image_names_c = list(children_balanced_df_i[children_balanced_df_i[\"identity_name\"].isin(non_enrolled_identity_names_c)].image_name)\n",
    "    all_reference_image_names_c = list(children_balanced_df_i.image_name)\n",
    "\n",
    "    ### All reference image names, enrolled and non-enrolled image names - adults ###\n",
    "    a_mates = adults_balanced_df_i.groupby(\"identity_name\").agg({'identity_name': ['count']})\n",
    "    enrolled_identity_names_a = a_mates[a_mates[('identity_name', 'count')] > 1].index\n",
    "    enrolled_image_names_a = list(adults_balanced_df_i[adults_balanced_df_i[\"identity_name\"].isin(enrolled_identity_names_a)].image_name)\n",
    "    non_enrolled_identity_names_a = a_mates[a_mates[('identity_name', 'count')] == 1].index\n",
    "    non_enrolled_image_names_a = list(adults_balanced_df_i[adults_balanced_df_i[\"identity_name\"].isin(non_enrolled_identity_names_a)].image_name)\n",
    "    all_reference_image_names_a = list(adults_balanced_df_i.image_name)\n",
    "\n",
    "    ### Similarity matrices for ids in reference database ###\n",
    "    indices_c_all_reference = [image_names_c.index(name) for name in all_reference_image_names_c]\n",
    "    indices_a_all_reference = [image_names_a.index(name) for name in all_reference_image_names_a]\n",
    "\n",
    "    # Extract corresponding columns from the similarity matrix\n",
    "    sim_mat_c_reference_cols = sim_mat_c[:, indices_c_all_reference]\n",
    "    sim_mat_a_reference_cols = sim_mat_a[:, indices_a_all_reference]\n",
    "\n",
    "    # Extract corresponding rows from the numerical ids\n",
    "    num_ids_c_reference = num_ids_c[indices_c_all_reference]\n",
    "    num_ids_a_reference = num_ids_a[indices_a_all_reference]\n",
    "\n",
    "\n",
    "    ### Similarity matrices for non-enrolled ids ###\n",
    "    # Get indices of all feature and numerical id elements that are non-enrolled  ids\n",
    "    indices_c_non_enrolled = [image_names_c.index(name) for name in non_enrolled_image_names_c]\n",
    "    indices_a_non_enrolled = [image_names_a.index(name) for name in non_enrolled_image_names_a]\n",
    "\n",
    "\n",
    "    # Extract corresponding rows from the similarity matrix\n",
    "    sim_mat_c_non_enrolled_0 = sim_mat_c_reference_cols[indices_c_non_enrolled]\n",
    "    sim_mat_a_non_enrolled_0 = sim_mat_a_reference_cols[indices_a_non_enrolled]\n",
    "\n",
    "    # Extract corresponding rows from the numerical ids\n",
    "    num_ids_c_non_enrolled = num_ids_c[indices_c_non_enrolled]\n",
    "    num_ids_a_non_enrolled = num_ids_a[indices_a_non_enrolled]\n",
    "\n",
    "\n",
    "    ### Similarity matrices for enrolled ids ###\n",
    "    # Get indices of all feature and numerical id elements that are enrolled ids\n",
    "    indices_c_enrolled = [image_names_c.index(name) for name in enrolled_image_names_c]\n",
    "    indices_a_enrolled = [image_names_a.index(name) for name in enrolled_image_names_a]\n",
    "\n",
    "    # Extract corresponding rows from the similarity matrix\n",
    "    sim_mat_c_enrolled_0 = sim_mat_c[np.ix_(indices_c_enrolled, indices_c_enrolled)] # only enrolled columns and rows\n",
    "    sim_mat_a_enrolled_0 = sim_mat_a[np.ix_(indices_a_enrolled, indices_a_enrolled)]\n",
    "\n",
    "    # Extract corresponding rows from the numerical ids\n",
    "    num_ids_c_enrolled = num_ids_c[indices_c_enrolled]\n",
    "    num_ids_a_enrolled = num_ids_a[indices_a_enrolled]\n",
    "\n",
    "\n",
    "    ### DET THINGS ###\n",
    "    thold = 0.48\n",
    "\n",
    "    ### Evaluation metrics ###\n",
    "    # FNIR\n",
    "    FNIR_c, sim_mat_c_enrolled = compute_fnir(sim_mat_c_enrolled_0, sim_mat_c, enrolled_identity_names_c, num_ids_c_enrolled, ids_c, thold=thold)\n",
    "    FNIR_a, sim_mat_a_enrolled = compute_fnir(sim_mat_a_enrolled_0, sim_mat_a, enrolled_identity_names_a, num_ids_a_enrolled, ids_a, thold=thold)\n",
    "    # FPIR\n",
    "    FPIR_c = compute_fpir(sim_mat_c_non_enrolled_0, num_ids_c_non_enrolled, num_ids_c_reference, thold=thold)\n",
    "    FPIR_a = compute_fpir(sim_mat_a_non_enrolled_0, num_ids_a_non_enrolled, num_ids_a_reference, thold=thold)\n",
    "\n",
    "\n",
    "    # OBS maybe compute Garbe outside funtion to choose a good alpha?\n",
    "    alpha_garbe = 0.47\n",
    "    FPD_i, FND_i, GARBE_i = GARBE(FNIR_c, FNIR_a, FPIR_c, FPIR_a, alpha=alpha_garbe)\n",
    "\n",
    "    FNIR_c_list.append(FNIR_c)\n",
    "    FNIR_a_list.append(FNIR_a)\n",
    "    FPIR_c_list.append(FPIR_c)\n",
    "    FPIR_a_list.append(FPIR_a)\n",
    "    FPD_list.append(FPD_i)\n",
    "    FND_list.append(FND_i)\n",
    "    GARBE_list.append(GARBE_i)\n",
    "\n",
    "    sim_mat_dict_all_magface_ex1_1['sim_mat_c_enrolled_iteration_{}'.format(random_state_i)]=sim_mat_c_enrolled\n",
    "    sim_mat_dict_all_magface_ex1_1['sim_mat_a_enrolled_iteration_{}'.format(random_state_i)]=sim_mat_a_enrolled\n",
    "    sim_mat_dict_all_magface_ex1_1['sim_mat_c_non_enrolled_iteration_{}'.format(random_state_i)]=remove_ones(sim_mat_c_non_enrolled_0)\n",
    "    sim_mat_dict_all_magface_ex1_1['sim_mat_a_non_enrolled_iteration_{}'.format(random_state_i)]=remove_ones(sim_mat_a_non_enrolled_0)\n",
    "\n",
    "\n",
    "    print(\"done\")\n",
    "\n",
    "# Create a DataFrame from the lists\n",
    "data = {'Iteration': random_states,'FNIR_c': FNIR_c_list, 'FNIR_a': FNIR_a_list, \"FPIR_c\": FPIR_c_list, \"FPIR_a\": FPIR_a_list, \"FPD\": FPD_list, \"FND\": FND_list, \"GARBE\": GARBE_list, \"Threshold\": thold}\n",
    "df_all_results = pd.DataFrame(data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Katrine_MLOps_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
